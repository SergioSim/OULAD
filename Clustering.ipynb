{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering of OULAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.filter_oulad as filter_oulad\n",
    "from tools.load_oulad import dataset_dict\n",
    "from tools.validation_oulad import customClusteringScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_mean</th>\n",
       "      <th>score_sum</th>\n",
       "      <th>date_submitted_mean</th>\n",
       "      <th>is_banked_sum</th>\n",
       "      <th>assessment_type_CMA_count</th>\n",
       "      <th>assessment_type_TMA_count</th>\n",
       "      <th>date_mean</th>\n",
       "      <th>weight_mean</th>\n",
       "      <th>weight_sum</th>\n",
       "      <th>gender_first</th>\n",
       "      <th>region_first</th>\n",
       "      <th>highest_education_first</th>\n",
       "      <th>imd_band_first</th>\n",
       "      <th>age_band_first</th>\n",
       "      <th>num_of_prev_attempts_first</th>\n",
       "      <th>studied_credits_first</th>\n",
       "      <th>disability_first</th>\n",
       "      <th>final_result_first</th>\n",
       "      <th>date_registration_first</th>\n",
       "      <th>date_unregistration_first</th>\n",
       "      <th>sum_click_mean</th>\n",
       "      <th>sum_click_sum</th>\n",
       "      <th>activity_type_subpage</th>\n",
       "      <th>activity_type_url</th>\n",
       "      <th>activity_type_homepage</th>\n",
       "      <th>activity_type_resource</th>\n",
       "      <th>activity_type_oucontent</th>\n",
       "      <th>activity_type_quiz</th>\n",
       "      <th>activity_type_forumng</th>\n",
       "      <th>activity_type_oucollaborate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_student</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28418</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.027027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29764</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.878788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>4.848485</td>\n",
       "      <td>160.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29820</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>1.644737</td>\n",
       "      <td>125.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40333</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.573770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.360656</td>\n",
       "      <td>144.0</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40604</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.242424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>1.772727</td>\n",
       "      <td>117.0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.136364</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686578</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.458333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692327</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.690909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>275.0</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697181</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.345133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>3.185841</td>\n",
       "      <td>360.0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698535</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3.989899</td>\n",
       "      <td>395.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1577 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            score_mean  score_sum  date_submitted_mean  is_banked_sum  \\\n",
       "id_student                                                              \n",
       "28418              0.0        0.0                 -1.0            0.0   \n",
       "29764              0.0        0.0                 -1.0            0.0   \n",
       "29820              0.0        0.0                 -1.0            0.0   \n",
       "40333              0.0        0.0                 -1.0            0.0   \n",
       "40604              0.0        0.0                 -1.0            0.0   \n",
       "...                ...        ...                  ...            ...   \n",
       "2681198            0.0        0.0                 -1.0            0.0   \n",
       "2686578            0.0        0.0                 -1.0            0.0   \n",
       "2692327            0.0        0.0                 -1.0            0.0   \n",
       "2697181            0.0        0.0                 -1.0            0.0   \n",
       "2698535            0.0        0.0                 -1.0            0.0   \n",
       "\n",
       "            assessment_type_CMA_count  assessment_type_TMA_count  date_mean  \\\n",
       "id_student                                                                    \n",
       "28418                               0                          0   9.027027   \n",
       "29764                               0                          0  -1.878788   \n",
       "29820                               0                          0   1.578947   \n",
       "40333                               0                          0   1.573770   \n",
       "40604                               0                          0  -5.242424   \n",
       "...                               ...                        ...        ...   \n",
       "2681198                             0                          0  -6.363636   \n",
       "2686578                             0                          0   4.458333   \n",
       "2692327                             0                          0  -7.690909   \n",
       "2697181                             0                          0   0.345133   \n",
       "2698535                             0                          0   5.333333   \n",
       "\n",
       "            weight_mean  weight_sum  gender_first  region_first  \\\n",
       "id_student                                                        \n",
       "28418               0.0         0.0             0            11   \n",
       "29764               0.0         0.0             1             0   \n",
       "29820               0.0         0.0             1             0   \n",
       "40333               0.0         0.0             1             4   \n",
       "40604               0.0         0.0             1             2   \n",
       "...                 ...         ...           ...           ...   \n",
       "2681198             0.0         0.0             1             0   \n",
       "2686578             0.0         0.0             1             6   \n",
       "2692327             0.0         0.0             1             4   \n",
       "2697181             0.0         0.0             0             6   \n",
       "2698535             0.0         0.0             1            10   \n",
       "\n",
       "            highest_education_first  imd_band_first  age_band_first  \\\n",
       "id_student                                                            \n",
       "28418                             2              25               0   \n",
       "29764                             2              55               0   \n",
       "29820                             3              45               0   \n",
       "40333                             3               5               1   \n",
       "40604                             2               0               1   \n",
       "...                             ...             ...             ...   \n",
       "2681198                           1              75               1   \n",
       "2686578                           2              65               0   \n",
       "2692327                           2               0               1   \n",
       "2697181                           3              65               0   \n",
       "2698535                           1              55               0   \n",
       "\n",
       "            num_of_prev_attempts_first  studied_credits_first  \\\n",
       "id_student                                                      \n",
       "28418                                0                     30   \n",
       "29764                                0                     90   \n",
       "29820                                0                     60   \n",
       "40333                                0                     30   \n",
       "40604                                0                     30   \n",
       "...                                ...                    ...   \n",
       "2681198                              0                     90   \n",
       "2686578                              0                     90   \n",
       "2692327                              0                     60   \n",
       "2697181                              0                     40   \n",
       "2698535                              0                     60   \n",
       "\n",
       "            disability_first  final_result_first  date_registration_first  \\\n",
       "id_student                                                                  \n",
       "28418                      0                   1                    -37.0   \n",
       "29764                      0                   3                    -34.0   \n",
       "29820                      0                   2                    -57.0   \n",
       "40333                      0                   0                    -30.0   \n",
       "40604                      0                   2                    -17.0   \n",
       "...                      ...                 ...                      ...   \n",
       "2681198                    0                   0                   -225.0   \n",
       "2686578                    0                   3                    -23.0   \n",
       "2692327                    0                   3                    -25.0   \n",
       "2697181                    0                   2                   -186.0   \n",
       "2698535                    0                   0                   -156.0   \n",
       "\n",
       "            date_unregistration_first  sum_click_mean  sum_click_sum  \\\n",
       "id_student                                                             \n",
       "28418                           241.0        2.000000           74.0   \n",
       "29764                           241.0        4.848485          160.0   \n",
       "29820                           241.0        1.644737          125.0   \n",
       "40333                            17.0        2.360656          144.0   \n",
       "40604                           241.0        1.772727          117.0   \n",
       "...                               ...             ...            ...   \n",
       "2681198                         133.0        2.136364           47.0   \n",
       "2686578                         241.0        1.166667           28.0   \n",
       "2692327                         241.0        2.500000          275.0   \n",
       "2697181                         241.0        3.185841          360.0   \n",
       "2698535                         180.0        3.989899          395.0   \n",
       "\n",
       "            activity_type_subpage  activity_type_url  activity_type_homepage  \\\n",
       "id_student                                                                     \n",
       "28418                          16                  1                       4   \n",
       "29764                           6                  3                       8   \n",
       "29820                          15                  2                      15   \n",
       "40333                          17                  7                      13   \n",
       "40604                          21                  3                      16   \n",
       "...                           ...                ...                     ...   \n",
       "2681198                         4                  1                       7   \n",
       "2686578                         6                  1                       4   \n",
       "2692327                        58                  9                      12   \n",
       "2697181                        33                  3                      16   \n",
       "2698535                        18                  4                      16   \n",
       "\n",
       "            activity_type_resource  activity_type_oucontent  \\\n",
       "id_student                                                    \n",
       "28418                           10                        1   \n",
       "29764                            2                        6   \n",
       "29820                           26                        2   \n",
       "40333                           12                        3   \n",
       "40604                           12                        7   \n",
       "...                            ...                      ...   \n",
       "2681198                          4                        2   \n",
       "2686578                          8                        1   \n",
       "2692327                         19                        1   \n",
       "2697181                         11                        2   \n",
       "2698535                         12                        4   \n",
       "\n",
       "            activity_type_quiz  activity_type_forumng  \\\n",
       "id_student                                              \n",
       "28418                        5                      0   \n",
       "29764                        7                      1   \n",
       "29820                        3                     13   \n",
       "40333                        5                      4   \n",
       "40604                        3                      4   \n",
       "...                        ...                    ...   \n",
       "2681198                      4                      0   \n",
       "2686578                      4                      0   \n",
       "2692327                     10                      1   \n",
       "2697181                     25                     23   \n",
       "2698535                     17                     28   \n",
       "\n",
       "            activity_type_oucollaborate  \n",
       "id_student                               \n",
       "28418                                 0  \n",
       "29764                                 0  \n",
       "29820                                 0  \n",
       "40333                                 0  \n",
       "40604                                 0  \n",
       "...                                 ...  \n",
       "2681198                               0  \n",
       "2686578                               0  \n",
       "2692327                               0  \n",
       "2697181                               0  \n",
       "2698535                               0  \n",
       "\n",
       "[1577 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code_module = 'CCC'\n",
    "code_presentation = '2014B'\n",
    "oneCourse = filter_oulad.getOneCourse(dataset_dict, code_module, code_presentation)\n",
    "final_df = filter_oulad.restructure(oneCourse, 14)\n",
    "encoders = filter_oulad.cleanAndMap(final_df)\n",
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       score_mean  score_sum  date_submitted_mean  is_banked_sum  \\\n",
      "count      1577.0     1577.0               1577.0         1577.0   \n",
      "mean          0.0        0.0                 -1.0            0.0   \n",
      "std           0.0        0.0                  0.0            0.0   \n",
      "min           0.0        0.0                 -1.0            0.0   \n",
      "25%           0.0        0.0                 -1.0            0.0   \n",
      "50%           0.0        0.0                 -1.0            0.0   \n",
      "75%           0.0        0.0                 -1.0            0.0   \n",
      "max           0.0        0.0                 -1.0            0.0   \n",
      "\n",
      "       assessment_type_CMA_count  assessment_type_TMA_count    date_mean  \\\n",
      "count                     1577.0                     1577.0  1577.000000   \n",
      "mean                         0.0                        0.0     1.723750   \n",
      "std                          0.0                        0.0     5.068600   \n",
      "min                          0.0                        0.0   -18.000000   \n",
      "25%                          0.0                        0.0    -1.117647   \n",
      "50%                          0.0                        0.0     2.028736   \n",
      "75%                          0.0                        0.0     4.928571   \n",
      "max                          0.0                        0.0    14.000000   \n",
      "\n",
      "       weight_mean  weight_sum  gender_first  region_first  \\\n",
      "count       1577.0      1577.0   1577.000000   1577.000000   \n",
      "mean           0.0         0.0      0.769182      5.850349   \n",
      "std            0.0         0.0      0.421490      3.603675   \n",
      "min            0.0         0.0      0.000000      0.000000   \n",
      "25%            0.0         0.0      1.000000      3.000000   \n",
      "50%            0.0         0.0      1.000000      6.000000   \n",
      "75%            0.0         0.0      1.000000      9.000000   \n",
      "max            0.0         0.0      1.000000     12.000000   \n",
      "\n",
      "       highest_education_first  imd_band_first  age_band_first  \\\n",
      "count              1577.000000     1577.000000     1577.000000   \n",
      "mean                  1.983513       47.742549        0.287888   \n",
      "std                   0.812955       30.039245        0.470783   \n",
      "min                   0.000000        0.000000        0.000000   \n",
      "25%                   1.000000       25.000000        0.000000   \n",
      "50%                   2.000000       45.000000        0.000000   \n",
      "75%                   3.000000       75.000000        1.000000   \n",
      "max                   4.000000       95.000000        2.000000   \n",
      "\n",
      "       num_of_prev_attempts_first  studied_credits_first  disability_first  \\\n",
      "count                      1577.0            1577.000000       1577.000000   \n",
      "mean                          0.0              72.079899          0.084971   \n",
      "std                           0.0              38.156503          0.278928   \n",
      "min                           0.0              30.000000          0.000000   \n",
      "25%                           0.0              60.000000          0.000000   \n",
      "50%                           0.0              60.000000          0.000000   \n",
      "75%                           0.0              90.000000          0.000000   \n",
      "max                           0.0             630.000000          1.000000   \n",
      "\n",
      "       final_result_first  date_registration_first  date_unregistration_first  \\\n",
      "count         1577.000000              1577.000000                1577.000000   \n",
      "mean             1.169943               -83.535193                 183.431833   \n",
      "std              1.060497                68.901139                  85.421034   \n",
      "min              0.000000              -311.000000                   3.000000   \n",
      "25%              0.000000              -127.000000                 111.000000   \n",
      "50%              1.000000               -58.000000                 241.000000   \n",
      "75%              2.000000               -25.000000                 241.000000   \n",
      "max              3.000000                12.000000                 241.000000   \n",
      "\n",
      "       sum_click_mean  sum_click_sum  activity_type_subpage  \\\n",
      "count     1577.000000    1577.000000            1577.000000   \n",
      "mean         3.173519     197.194039              11.628408   \n",
      "std          1.768327     268.921172              15.666946   \n",
      "min          1.000000       1.000000               0.000000   \n",
      "25%          2.000000      40.000000               2.000000   \n",
      "50%          2.785714     110.000000               7.000000   \n",
      "75%          3.928571     253.000000              16.000000   \n",
      "max         18.625000    3907.000000             252.000000   \n",
      "\n",
      "       activity_type_url  activity_type_homepage  activity_type_resource  \\\n",
      "count        1577.000000             1577.000000             1577.000000   \n",
      "mean            2.140774                9.117945                8.086240   \n",
      "std             2.582245                6.581877                8.505085   \n",
      "min             0.000000                0.000000                0.000000   \n",
      "25%             1.000000                4.000000                2.000000   \n",
      "50%             1.000000                8.000000                6.000000   \n",
      "75%             3.000000               13.000000               11.000000   \n",
      "max            32.000000               33.000000               98.000000   \n",
      "\n",
      "       activity_type_oucontent  activity_type_quiz  activity_type_forumng  \\\n",
      "count              1577.000000         1577.000000            1577.000000   \n",
      "mean                  3.268865           10.099556               7.840837   \n",
      "std                   3.753002           12.650549              13.707168   \n",
      "min                   0.000000            0.000000               0.000000   \n",
      "25%                   0.000000            1.000000               0.000000   \n",
      "50%                   2.000000            6.000000               2.000000   \n",
      "75%                   5.000000           14.000000               9.000000   \n",
      "max                  23.000000          141.000000              92.000000   \n",
      "\n",
      "       activity_type_oucollaborate  \n",
      "count                  1577.000000  \n",
      "mean                      0.139505  \n",
      "std                       0.447291  \n",
      "min                       0.000000  \n",
      "25%                       0.000000  \n",
      "50%                       0.000000  \n",
      "75%                       0.000000  \n",
      "max                       4.000000  \n",
      "REGION REPARTITION\n",
      "region_first\n",
      "0     156\n",
      "1      97\n",
      "2      58\n",
      "3     151\n",
      "4     111\n",
      "5     134\n",
      "6     235\n",
      "7      82\n",
      "8     149\n",
      "9      95\n",
      "10     81\n",
      "11    131\n",
      "12     97\n",
      "dtype: int64\n",
      "EDUCATION REPARTITION\n",
      "highest_education_first\n",
      "0     12\n",
      "1    451\n",
      "2    712\n",
      "3    355\n",
      "4     47\n",
      "dtype: int64\n",
      "FINAL RESULT REPARTITION\n",
      "0    583\n",
      "2    467\n",
      "1    335\n",
      "3    192\n",
      "Name: final_result_first, dtype: int64\n",
      "final_df contains 0 NaNs\n"
     ]
    }
   ],
   "source": [
    "# some information about the final_df\n",
    "print(final_df.describe(include='all'))\n",
    "print('REGION REPARTITION')\n",
    "print(final_df.groupby('region_first').size())\n",
    "print('EDUCATION REPARTITION')\n",
    "print(final_df.groupby('highest_education_first').size())\n",
    "print('FINAL RESULT REPARTITION')\n",
    "print(final_df['final_result_first'].value_counts())\n",
    "# to check that we don't have NaNs!\n",
    "print('final_df contains %i NaNs' % sum(final_df.isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "#### IDEA:\n",
    "- imagine the course just started - we are at week 2\n",
    "- we want to identify students which might Fail/Withdraw to propose them help\n",
    "- to start of simple we don't try to predict WHEN a student will Fail/Withdraw and we ignore all student interactions with other courses\n",
    "- we suppose that students that Fail/Withdraw can be distinguished by their behaviour and features but we don't know which ones in advance\n",
    "- with clustering we can identify groups of student that are similar\n",
    "- we suppose that students that have similar behaviour / features would have similar outcomes\n",
    "\n",
    "- we want to measure if the resulting groups could provide useful information for a set of prediction algorithms thereby improving their predictions \n",
    "\n",
    "- how does the quality of the generated groups impact the predictors?\n",
    "\n",
    "- could a consensus clustering algorithm produce an even better set of groups to improve even more the prediction?\n",
    "- how does the clustering algorithms generalise for differenes courses / the same course the next year?\n",
    "- if each time the optimal hyper params are different - could the consensus clustering \n",
    "   algorithm solve this issue by combining multiple choices of hyper params at the same time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate response label from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another solution would be to cluster a previous course (training) and use the current one for\n",
    "#   prediction ... for now we want just to measure the clustering quality on all the data\n",
    "# train, test = train_test_split(final_df, random_state=0)\n",
    "scaler = MinMaxScaler()\n",
    "trainX = final_df.drop(['final_result_first'], axis=1)\n",
    "trainX = scaler.fit_transform(trainX)\n",
    "testY = final_df['final_result_first']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Used clustering algorithms and their hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.clustering_parameters as params\n",
    "clustAlgos = {\n",
    "    \"kMeans\": {\n",
    "        'obj': KMeans, \n",
    "        'params': params.kmeansParams,\n",
    "        'paramRanges': {'n_clusters' : range(3, 4)}\n",
    "    },\n",
    "    \"kMedoits\": {\n",
    "        'obj': KMedoids, \n",
    "        'params': params.kMedoidsParams,\n",
    "        'paramRanges': {'n_clusters' : range(2, 4)}\n",
    "    },\n",
    "    \"SpectralClustering\": {\n",
    "        'obj': SpectralClustering,\n",
    "        'params': params.spectralClusteringParams,\n",
    "        'paramRanges': {'n_clusters' : range(3, 5)}\n",
    "    },\n",
    "#     \"AgglomerativeClustering\": {\n",
    "#         'obj': AgglomerativeClustering,\n",
    "#         'params': params.agglomerativeClusteringParams,\n",
    "#         'paramRanges': {'n_clusters' : range(2, 4)}\n",
    "#     },\n",
    "#     \"Birch\": {\n",
    "#         'obj': Birch, \n",
    "#         'params': params.birchParams,\n",
    "#         'paramRanges': {'n_clusters' : range(2, 4)}\n",
    "#     },\n",
    "    \n",
    "    # density based - don't use nb_clusters\n",
    "#     \"DBSCAN\": {'obj': DBSCAN, 'params': params.dbscanParams},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the baseClusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6/6 (100%)\n",
      "BASE CLUSTERINGS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_student</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28418</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29764</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29820</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40333</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40604</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681198</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686578</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692327</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697181</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698535</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1577 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1  2  3  4  5  6\n",
       "id_student                  \n",
       "28418       2  2  1  1  2  0\n",
       "29764       0  0  0  0  0  1\n",
       "29820       0  0  0  0  0  1\n",
       "40333       1  1  0  0  1  3\n",
       "40604       0  0  0  0  0  1\n",
       "...        .. .. .. .. .. ..\n",
       "2681198     1  1  0  0  1  3\n",
       "2686578     0  0  1  2  1  1\n",
       "2692327     0  0  0  0  0  1\n",
       "2697181     2  2  1  2  2  0\n",
       "2698535     0  0  1  1  0  1\n",
       "\n",
       "[1577 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM CLUSTERING SCORE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpectralClustering_k</th>\n",
       "      <th>SpectralClustering_type</th>\n",
       "      <th>SpectralClustering_score</th>\n",
       "      <th>kMeans_k</th>\n",
       "      <th>kMeans_type</th>\n",
       "      <th>kMeans_score</th>\n",
       "      <th>kMedoits_k</th>\n",
       "      <th>kMedoits_type</th>\n",
       "      <th>kMedoits_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>affinity=laplacian</td>\n",
       "      <td>0.400127</td>\n",
       "      <td>3</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.302473</td>\n",
       "      <td>3</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.381103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>affinity=laplacian</td>\n",
       "      <td>0.306278</td>\n",
       "      <td>3</td>\n",
       "      <td>tol=5</td>\n",
       "      <td>0.302473</td>\n",
       "      <td>2</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.164236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SpectralClustering_k SpectralClustering_type  SpectralClustering_score  \\\n",
       "0                    3      affinity=laplacian                  0.400127   \n",
       "1                    4      affinity=laplacian                  0.306278   \n",
       "2                  NaN                     NaN                       NaN   \n",
       "3                  NaN                     NaN                       NaN   \n",
       "4                  NaN                     NaN                       NaN   \n",
       "5                  NaN                     NaN                       NaN   \n",
       "6                  NaN                     NaN                       NaN   \n",
       "7                  NaN                     NaN                       NaN   \n",
       "8                  NaN                     NaN                       NaN   \n",
       "9                  NaN                     NaN                       NaN   \n",
       "\n",
       "  kMeans_k kMeans_type  kMeans_score kMedoits_k kMedoits_type  kMedoits_score  \n",
       "0        3     vanilla      0.302473          3       vanilla        0.381103  \n",
       "1        3       tol=5      0.302473          2       vanilla        0.164236  \n",
       "2      NaN         NaN           NaN        NaN           NaN             NaN  \n",
       "3      NaN         NaN           NaN        NaN           NaN             NaN  \n",
       "4      NaN         NaN           NaN        NaN           NaN             NaN  \n",
       "5      NaN         NaN           NaN        NaN           NaN             NaN  \n",
       "6      NaN         NaN           NaN        NaN           NaN             NaN  \n",
       "7      NaN         NaN           NaN        NaN           NaN             NaN  \n",
       "8      NaN         NaN           NaN        NaN           NaN             NaN  \n",
       "9      NaN         NaN           NaN        NaN           NaN             NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1 Generate clustering ensemble of the dataset and store the clustering vectors in a \n",
    "#   list BaseClusterings\n",
    "baseClusterings = pd.DataFrame(index=testY.index)\n",
    "results = pd.DataFrame(columns=['k', 'algo', 'type', 'score'])\n",
    "stepCount = 0\n",
    "totalStepsCount = sum([len(clustAlgos[key]['params']) * \\\n",
    "                       sum([len(clustAlgos[key]['paramRanges'][innerkey]) \\\n",
    "                            for innerkey in clustAlgos[key]['paramRanges']]) \\\n",
    "                            for key in clustAlgos])\n",
    "\n",
    "for clustAlgoKey in clustAlgos:\n",
    "    for paramsKey in clustAlgos[clustAlgoKey]['params']:\n",
    "        for rangedParamKey in clustAlgos[clustAlgoKey]['paramRanges']:\n",
    "            for rangedParamValue in clustAlgos[clustAlgoKey]['paramRanges'][rangedParamKey]:\n",
    "                # for for for for for for for for ...\n",
    "                clear_output(wait=True)\n",
    "                clustAlgos[clustAlgoKey]['params'][paramsKey][rangedParamKey] = \\\n",
    "                                rangedParamValue\n",
    "                clustAlgo = clustAlgos[clustAlgoKey]['obj'](\\\n",
    "                                **clustAlgos[clustAlgoKey]['params'][paramsKey])\n",
    "                clustAlgo.fit(trainX)\n",
    "                # we don't want to predict - for now only evaluate the quality of the clustering\n",
    "                # clustAlgo_predict = pd.Series(clustAlgo.predict(trainX), name=clustAlgoKey, \\\n",
    "                # index=testY.index)\n",
    "                clustAlgo_labels = pd.Series(clustAlgo.labels_, name=clustAlgoKey, \\\n",
    "                                             index=testY.index)\n",
    "                baseClusterings.insert(len(baseClusterings.columns), str(stepCount+1), \\\n",
    "                                       clustAlgo_labels)\n",
    "\n",
    "                results = results.append({\n",
    "                    'k': rangedParamValue, \n",
    "                    'algo': clustAlgoKey, \n",
    "                    'type': paramsKey, \n",
    "                    'score': customClusteringScore(clustAlgo_labels, testY) \n",
    "                    }, ignore_index=True)\n",
    "                stepCount += 1\n",
    "                print('step %i/%i (%i%s)' % (stepCount, totalStepsCount, \\\n",
    "                                             round(100 * stepCount/totalStepsCount,2), '%'))\n",
    "\n",
    "nb_lines = 10\n",
    "resultTable = pd.DataFrame(index=range(0,nb_lines))\n",
    "for group in results.sort_values(by='score', ascending=False).groupby(['algo']):\n",
    "    if len(group[1]) < nb_lines:\n",
    "        group = (group[0], group[1].append([x for x in [0] * nb_lines]))\n",
    "    \n",
    "    resultTable.insert(len(resultTable.columns), \"%s_k\" % \\\n",
    "                       (group[0]), group[1].head(nb_lines)['k'].values)\n",
    "    resultTable.insert(len(resultTable.columns), \"%s_type\" % \\\n",
    "                       (group[0]), group[1].head(nb_lines)['type'].values)\n",
    "    resultTable.insert(len(resultTable.columns), \"%s_score\" % \\\n",
    "                       (group[0]), group[1].head(nb_lines)['score'].values)\n",
    "\n",
    "print(\"BASE CLUSTERINGS\")\n",
    "display(baseClusterings)\n",
    "print(\"CUSTOM CLUSTERING SCORE\")\n",
    "display(resultTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiCons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# D= {1,2,3,4,5,6,7,8,9} partitioned using five base clusterings into the five partitions:\n",
    "# P1 = {{1,2,3},{4,5,6,7,8,9}},\n",
    "# P2 = {{1,2,3},{4,5,6,7,8,9}},\n",
    "# P3 = {{1,2,3,4,5},{6,7},{8,9}},\n",
    "# P4 = {{4,5,6,7}, {1,2,3},{8,9}}\n",
    "# P5 = {{4,5,6,7},{1,2,3},{8,9}}\n",
    "clust = pd.DataFrame(index=range(1,10))\n",
    "membershipMatrix = pd.DataFrame(index=range(1,10))\n",
    "clust.insert(len(clust.columns), '1', [0,0,0,1,1,1,1,1,1])\n",
    "clust.insert(len(clust.columns), '2', [0,0,0,1,1,1,1,1,1])\n",
    "clust.insert(len(clust.columns), '3', [0,0,0,0,0,1,1,2,2])\n",
    "clust.insert(len(clust.columns), '4', [1,1,1,0,0,0,0,2,2])\n",
    "clust.insert(len(clust.columns), '5', [1,1,1,0,0,0,0,2,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseClusterings = clust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Membership matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1P0</th>\n",
       "      <th>1P1</th>\n",
       "      <th>1P2</th>\n",
       "      <th>2P0</th>\n",
       "      <th>2P1</th>\n",
       "      <th>2P2</th>\n",
       "      <th>3P0</th>\n",
       "      <th>3P1</th>\n",
       "      <th>4P0</th>\n",
       "      <th>4P1</th>\n",
       "      <th>4P2</th>\n",
       "      <th>5P0</th>\n",
       "      <th>5P1</th>\n",
       "      <th>5P2</th>\n",
       "      <th>6P0</th>\n",
       "      <th>6P1</th>\n",
       "      <th>6P2</th>\n",
       "      <th>6P3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_student</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28418</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29764</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29820</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40333</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40604</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686578</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692327</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697181</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698535</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1577 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1P0  1P1  1P2  2P0  2P1  2P2  3P0  3P1  4P0  4P1  4P2  5P0  5P1  \\\n",
       "id_student                                                                    \n",
       "28418         0    0    1    0    0    1    0    1    0    1    0    0    0   \n",
       "29764         1    0    0    1    0    0    1    0    1    0    0    1    0   \n",
       "29820         1    0    0    1    0    0    1    0    1    0    0    1    0   \n",
       "40333         0    1    0    0    1    0    1    0    1    0    0    0    1   \n",
       "40604         1    0    0    1    0    0    1    0    1    0    0    1    0   \n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "2681198       0    1    0    0    1    0    1    0    1    0    0    0    1   \n",
       "2686578       1    0    0    1    0    0    0    1    0    0    1    0    1   \n",
       "2692327       1    0    0    1    0    0    1    0    1    0    0    1    0   \n",
       "2697181       0    0    1    0    0    1    0    1    0    0    1    0    0   \n",
       "2698535       1    0    0    1    0    0    0    1    0    1    0    1    0   \n",
       "\n",
       "            5P2  6P0  6P1  6P2  6P3  \n",
       "id_student                           \n",
       "28418         1    1    0    0    0  \n",
       "29764         0    0    1    0    0  \n",
       "29820         0    0    1    0    0  \n",
       "40333         0    0    0    0    1  \n",
       "40604         0    0    1    0    0  \n",
       "...         ...  ...  ...  ...  ...  \n",
       "2681198       0    0    0    0    1  \n",
       "2686578       0    0    1    0    0  \n",
       "2692327       0    0    1    0    0  \n",
       "2697181       1    1    0    0    0  \n",
       "2698535       0    0    1    0    0  \n",
       "\n",
       "[1577 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there should be a much better way to construct the membership matrix...\n",
    "# for now let's use a naive implementation\n",
    "\n",
    "# 3 Build the cluster membership matrix M\n",
    "def buildMembershipMatrix(baseClusterings):\n",
    "    ''' Computes and returns the Membership matrix'''\n",
    "    membershipMatrix = pd.DataFrame(index=baseClusterings.index)\n",
    "    for col in baseClusterings.columns:\n",
    "        for partition in np.sort(baseClusterings[col].unique()):\n",
    "            membershipMatrix.insert(len(membershipMatrix.columns), '%sP%i' % (col, partition), baseClusterings[col] == partition)\n",
    "    return membershipMatrix\n",
    "\n",
    "membershipMatrix = buildMembershipMatrix(baseClusterings)\n",
    "membershipMatrix.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate FCPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python elapsed time: 773.0 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['1P1', '2P1', '3P1', '4P2', '5P1', '6P1'],\n",
       " ['1P2', '2P2', '3P1', '4P2', '5P2', '6P0'],\n",
       " ['1P2', '2P2', '3P0', '4P2', '5P2', '6P0'],\n",
       " ['1P2', '2P2', '3P1', '4P0', '5P2', '6P0'],\n",
       " ['1P2', '2P2', '3P0', '4P0', '5P2', '6P0'],\n",
       " ['1P2', '2P2', '3P1', '4P1', '5P2', '6P0'],\n",
       " ['1P2', '2P2', '3P0', '4P1', '5P2', '6P0'],\n",
       " ['1P1', '2P1', '3P1', '4P2', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '3P0', '4P2', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '3P0', '4P0', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '3P1', '4P1', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '3P0', '4P1', '5P0', '6P2'],\n",
       " ['1P0', '2P0', '3P0', '4P2', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '3P1', '4P1', '5P1', '6P1'],\n",
       " ['1P0', '2P0', '3P1', '4P1', '5P0', '6P2'],\n",
       " ['1P0', '2P0', '3P1', '4P0', '5P1', '6P1'],\n",
       " ['1P1', '2P1', '3P1', '4P2', '5P0', '6P1'],\n",
       " ['1P1', '2P1', '3P0', '4P0', '5P1', '6P1'],\n",
       " ['1P2', '2P2', '3P0', '4P0', '5P2', '6P2'],\n",
       " ['1P2', '2P2', '3P0', '4P1', '5P2', '6P2'],\n",
       " ['1P0', '2P0', '3P0', '4P0', '5P0', '6P2'],\n",
       " ['1P2', '2P2', '3P0', '4P2', '5P2', '6P2'],\n",
       " ['1P0', '2P0', '3P1', '4P2', '5P0', '6P2'],\n",
       " ['1P0', '2P0', '3P1', '4P2', '5P1', '6P1'],\n",
       " ['1P2', '2P2', '3P1', '4P2', '5P2', '6P2'],\n",
       " ['1P2', '2P2', '3P1', '4P1', '5P2', '6P2'],\n",
       " ['1P0', '2P0', '3P1', '4P1', '5P0', '6P1'],\n",
       " ['1P0', '2P0', '3P0', '4P1', '5P0', '6P1'],\n",
       " ['1P0', '2P0', '3P0', '4P2', '5P0', '6P1'],\n",
       " ['1P0', '2P0', '3P1', '4P1', '5P1', '6P1'],\n",
       " ['1P1', '2P1', '3P1', '4P1', '5P1', '6P3'],\n",
       " ['1P1', '2P1', '3P0', '4P1', '5P1', '6P3'],\n",
       " ['1P1', '2P1', '3P1', '4P1', '5P0', '6P3'],\n",
       " ['1P1', '2P1', '3P0', '4P1', '5P0', '6P3'],\n",
       " ['1P0', '2P0', '3P0', '4P0', '5P0', '6P1'],\n",
       " ['1P0', '2P0', '3P1', '4P2', '5P0', '6P1'],\n",
       " ['1P1', '2P1', '3P1', '4P2', '5P1', '6P3'],\n",
       " ['1P1', '2P1', '3P0', '4P2', '5P0', '6P3'],\n",
       " ['1P1', '2P1', '3P1', '4P0', '5P1', '6P3'],\n",
       " ['1P1', '2P1', '3P0', '4P0', '5P1', '6P3'],\n",
       " ['1P1', '2P1', '3P0', '4P0', '5P0', '6P3'],\n",
       " ['1P0', '2P0', '3P0', '4P2', '5P1', '6P1'],\n",
       " ['1P0', '2P0', '3P0', '4P0', '5P1', '6P1'],\n",
       " ['1P0', '2P0', '3P1', '4P0', '5P0', '6P1'],\n",
       " ['1P1', '2P1', '3P1', '5P1', '6P1'],\n",
       " ['1P1', '2P1', '3P1', '4P2', '5P1'],\n",
       " ['1P0', '2P0', '3P1', '4P2', '6P1'],\n",
       " ['1P0', '2P0', '3P1', '4P2', '5P0'],\n",
       " ['1P0', '2P0', '3P1', '5P0', '6P1'],\n",
       " ['1P2', '2P2', '3P1', '5P2', '6P0'],\n",
       " ['1P2', '2P2', '4P2', '5P2', '6P0'],\n",
       " ['1P2', '2P2', '3P0', '5P2', '6P0'],\n",
       " ['1P2', '2P2', '4P0', '5P2', '6P0'],\n",
       " ['1P2', '2P2', '4P1', '5P2', '6P0'],\n",
       " ['1P1', '2P1', '3P1', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '4P2', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '3P0', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '4P1', '5P0', '6P2'],\n",
       " ['1P0', '2P0', '3P0', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '3P1', '4P2', '6P1'],\n",
       " ['1P1', '2P1', '3P1', '4P1', '5P1'],\n",
       " ['1P1', '2P1', '3P1', '4P1', '5P0'],\n",
       " ['1P1', '2P1', '3P0', '4P1', '5P0'],\n",
       " ['1P0', '2P0', '4P0', '5P1', '6P1'],\n",
       " ['1P0', '2P0', '3P1', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '3P1', '4P2', '5P0'],\n",
       " ['1P1', '2P1', '3P0', '4P2', '5P0'],\n",
       " ['1P1', '2P1', '3P0', '4P0', '5P1'],\n",
       " ['1P1', '2P1', '3P0', '4P0', '5P0'],\n",
       " ['1P2', '2P2', '3P1', '5P2', '6P2'],\n",
       " ['1P2', '2P2', '3P1', '4P2', '5P2'],\n",
       " ['1P2', '2P2', '3P0', '4P2', '5P2'],\n",
       " ['1P2', '2P2', '3P0', '4P0', '5P2'],\n",
       " ['1P2', '2P2', '3P1', '4P1', '5P2'],\n",
       " ['1P2', '2P2', '3P0', '4P1', '5P2'],\n",
       " ['1P2', '2P2', '3P0', '5P2', '6P2'],\n",
       " ['1P0', '2P0', '4P2', '5P0', '6P2'],\n",
       " ['1P0', '2P0', '3P1', '5P1', '6P1'],\n",
       " ['1P0', '2P0', '4P2', '5P1', '6P1'],\n",
       " ['1P2', '2P2', '4P2', '5P2', '6P2'],\n",
       " ['1P2', '2P2', '4P1', '5P2', '6P2'],\n",
       " ['1P0', '2P0', '3P1', '4P1', '5P0'],\n",
       " ['1P0', '2P0', '4P1', '5P0', '6P1'],\n",
       " ['1P0', '2P0', '3P0', '4P2', '5P0'],\n",
       " ['1P0', '2P0', '3P1', '4P1', '6P1'],\n",
       " ['1P1', '2P1', '3P1', '4P1', '6P3'],\n",
       " ['1P1', '2P1', '4P1', '5P1', '6P3'],\n",
       " ['1P1', '2P1', '3P0', '4P1', '6P3'],\n",
       " ['1P1', '2P1', '4P1', '5P0', '6P3'],\n",
       " ['1P0', '2P0', '3P0', '4P0', '5P0'],\n",
       " ['1P0', '2P0', '4P2', '5P0', '6P1'],\n",
       " ['1P1', '2P1', '3P1', '5P1', '6P3'],\n",
       " ['1P1', '2P1', '3P0', '5P1', '6P3'],\n",
       " ['1P1', '2P1', '3P0', '5P0', '6P3'],\n",
       " ['1P1', '2P1', '4P0', '5P1', '6P3'],\n",
       " ['1P1', '2P1', '3P0', '4P0', '6P3'],\n",
       " ['1P0', '2P0', '3P0', '5P0', '6P1'],\n",
       " ['1P0', '2P0', '3P0', '4P2', '6P1'],\n",
       " ['1P0', '2P0', '3P0', '5P1', '6P1'],\n",
       " ['1P0', '2P0', '3P0', '4P0', '6P1'],\n",
       " ['1P0', '2P0', '4P0', '5P0', '6P1'],\n",
       " ['1P0', '2P0', '3P1', '4P0', '6P1'],\n",
       " ['1P1', '2P1', '3P1', '5P1'],\n",
       " ['1P1', '2P1', '5P1', '6P1'],\n",
       " ['1P0', '2P0', '3P1', '4P2'],\n",
       " ['1P0', '2P0', '4P2', '6P1'],\n",
       " ['1P0', '2P0', '4P2', '5P0'],\n",
       " ['1P0', '2P0', '3P1', '5P0'],\n",
       " ['1P0', '2P0', '5P0', '6P1'],\n",
       " ['1P2', '2P2', '5P2', '6P0'],\n",
       " ['1P1', '2P1', '5P0', '6P2'],\n",
       " ['3P0', '4P2', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '3P1', '4P2'],\n",
       " ['1P1', '2P1', '3P1', '4P1'],\n",
       " ['1P1', '2P1', '4P1', '5P1'],\n",
       " ['1P1', '2P1', '3P0', '4P1'],\n",
       " ['1P1', '2P1', '4P1', '5P0'],\n",
       " ['3P1', '4P1', '5P0', '6P2'],\n",
       " ['1P0', '2P0', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '3P1', '6P1'],\n",
       " ['1P1', '2P1', '3P0', '5P1'],\n",
       " ['1P1', '2P1', '3P1', '5P0'],\n",
       " ['1P1', '2P1', '4P2', '5P0'],\n",
       " ['1P1', '2P1', '3P0', '5P0'],\n",
       " ['1P1', '2P1', '4P0', '5P1'],\n",
       " ['1P1', '2P1', '3P0', '4P0'],\n",
       " ['1P2', '2P2', '5P2', '6P2'],\n",
       " ['1P2', '2P2', '3P1', '5P2'],\n",
       " ['1P2', '2P2', '4P2', '5P2'],\n",
       " ['1P2', '2P2', '3P0', '5P2'],\n",
       " ['1P2', '2P2', '4P0', '5P2'],\n",
       " ['1P2', '2P2', '4P1', '5P2'],\n",
       " ['3P0', '4P0', '5P0', '6P2'],\n",
       " ['3P1', '4P2', '5P0', '6P2'],\n",
       " ['1P0', '2P0', '5P1', '6P1'],\n",
       " ['3P1', '4P2', '5P1', '6P1'],\n",
       " ['1P0', '2P0', '3P1', '6P1'],\n",
       " ['1P0', '2P0', '4P1', '5P0'],\n",
       " ['1P0', '2P0', '3P1', '4P1'],\n",
       " ['1P0', '2P0', '4P1', '6P1'],\n",
       " ['3P1', '4P1', '5P1', '6P1'],\n",
       " ['1P1', '2P1', '4P1', '6P3'],\n",
       " ['3P1', '4P2', '5P0', '6P1'],\n",
       " ['1P1', '2P1', '3P1', '6P3'],\n",
       " ['1P1', '2P1', '4P2', '6P3'],\n",
       " ['1P1', '2P1', '5P1', '6P3'],\n",
       " ['1P1', '2P1', '3P0', '6P3'],\n",
       " ['1P1', '2P1', '5P0', '6P3'],\n",
       " ['1P1', '2P1', '4P0', '6P3'],\n",
       " ['1P0', '2P0', '3P0', '5P0'],\n",
       " ['1P0', '2P0', '3P0', '6P1'],\n",
       " ['1P0', '2P0', '3P0', '4P2'],\n",
       " ['1P0', '2P0', '3P0', '4P0'],\n",
       " ['3P0', '4P0', '5P1', '6P1'],\n",
       " ['1P0', '2P0', '4P0', '5P0'],\n",
       " ['1P0', '2P0', '4P0', '6P1'],\n",
       " ['1P1', '2P1', '5P1'],\n",
       " ['1P0', '2P0', '4P2'],\n",
       " ['3P1', '4P2', '6P1'],\n",
       " ['3P1', '4P2', '5P0'],\n",
       " ['1P0', '2P0', '5P0'],\n",
       " ['3P1', '5P0', '6P1'],\n",
       " ['3P0', '5P0', '6P2'],\n",
       " ['1P1', '2P1', '3P1'],\n",
       " ['1P1', '2P1', '4P2'],\n",
       " ['1P1', '2P1', '4P1'],\n",
       " ['3P0', '4P1', '6P2'],\n",
       " ['4P1', '5P0', '6P2'],\n",
       " ['4P0', '5P1', '6P1'],\n",
       " ['1P1', '2P1', '6P1'],\n",
       " ['1P1', '2P1', '3P0'],\n",
       " ['1P1', '2P1', '5P0'],\n",
       " ['1P1', '2P1', '4P0'],\n",
       " ['1P2', '2P2', '5P2'],\n",
       " ['3P0', '4P0', '6P2'],\n",
       " ['3P1', '4P1', '6P2'],\n",
       " ['3P1', '4P2', '6P2'],\n",
       " ['3P0', '4P2', '6P2'],\n",
       " ['3P1', '5P0', '6P2'],\n",
       " ['4P2', '5P0', '6P2'],\n",
       " ['3P1', '5P1', '6P1'],\n",
       " ['3P1', '4P2', '5P1'],\n",
       " ['4P2', '5P1', '6P1'],\n",
       " ['1P0', '2P0', '6P1'],\n",
       " ['3P1', '4P1', '5P0'],\n",
       " ['3P0', '4P1', '5P0'],\n",
       " ['3P0', '4P2', '5P0'],\n",
       " ['1P0', '2P0', '4P1'],\n",
       " ['3P1', '4P1', '6P1'],\n",
       " ['3P1', '4P1', '5P1'],\n",
       " ['1P0', '2P0', '3P1'],\n",
       " ['3P0', '4P0', '5P0'],\n",
       " ['4P2', '5P0', '6P1'],\n",
       " ['1P1', '2P1', '6P3'],\n",
       " ['1P0', '2P0', '3P0'],\n",
       " ['3P0', '5P1', '6P1'],\n",
       " ['3P0', '4P0', '6P1'],\n",
       " ['3P0', '4P0', '5P1'],\n",
       " ['1P0', '2P0', '4P0'],\n",
       " ['3P1', '4P0', '5P1'],\n",
       " ['3P1', '4P2'],\n",
       " ['4P2', '6P1'],\n",
       " ['4P2', '5P0'],\n",
       " ['3P1', '5P0'],\n",
       " ['5P0', '6P1'],\n",
       " ['1P1', '2P1'],\n",
       " ['4P1', '6P2'],\n",
       " ['3P1', '6P2'],\n",
       " ['4P2', '6P2'],\n",
       " ['3P0', '6P2'],\n",
       " ['5P0', '6P2'],\n",
       " ['3P1', '5P1'],\n",
       " ['5P1', '6P1'],\n",
       " ['4P2', '5P1'],\n",
       " ['3P1', '6P1'],\n",
       " ['4P1', '5P0'],\n",
       " ['3P1', '4P1'],\n",
       " ['4P1', '6P1'],\n",
       " ['4P1', '5P1'],\n",
       " ['3P0', '4P1'],\n",
       " ['1P0', '2P0'],\n",
       " ['3P0', '5P0'],\n",
       " ['3P0', '6P1'],\n",
       " ['3P0', '4P2'],\n",
       " ['3P0', '5P1'],\n",
       " ['3P0', '4P0'],\n",
       " ['4P0', '5P0'],\n",
       " ['3P1', '4P0'],\n",
       " ['4P0', '6P1'],\n",
       " ['4P0', '5P1'],\n",
       " ['4P2'],\n",
       " ['5P0'],\n",
       " ['3P1'],\n",
       " ['6P2'],\n",
       " ['5P1'],\n",
       " ['6P1'],\n",
       " ['4P1'],\n",
       " ['3P0'],\n",
       " ['4P0']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thanks to https://github.com/slide-lig/plcmpp for the implementation of the LCM algorithm\n",
    "# It's cloned and build in the ./FCI directory\n",
    "\n",
    "start = time.time()\n",
    "groups = list(range(0,len(membershipMatrix.columns)))\n",
    "transactionList = [(membershipMatrix.iloc[x,:] * groups)[membershipMatrix.iloc[x,:]] for x in range(0, len(membershipMatrix))]\n",
    "\n",
    "file = open('./FCI/input.txt','w')\n",
    "for line in transactionList:\n",
    "    file.write(str(list(line)).replace('[', '').replace(',', '').replace(']', '') + '\\n')\n",
    "\n",
    "file.close()\n",
    "\n",
    "os.chdir(os.getcwd() + '/FCI')\n",
    "# 4 Generate FCPs from M for minsupport = 0\n",
    "subprocess.call(\"./runLCM.sh\")\n",
    "os.chdir(os.getcwd()[:-3])\n",
    "\n",
    "file = open('./FCI/output.txt','r')\n",
    "FCPs = []\n",
    "for line in file:\n",
    "    line = line.replace('\\n', '')\n",
    "    freq = line[:line.find('\t')]\n",
    "    line = np.array(list(map(int, line[line.find('\t')+1:].split(' '))))\n",
    "    line.sort()\n",
    "    FCPs.append(list(membershipMatrix.columns[line]))\n",
    "    \n",
    "file.close()\n",
    "end = time.time()\n",
    "print('Python elapsed time: ' + str(round((end - start), 3) * 1000) + ' ms')\n",
    "# 5 Sort the FCPs in ascending order according to the size of the instance sets\n",
    "FCPs.sort(key = len, reverse = True)\n",
    "FCPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consensusFunction10(biClust):\n",
    "    '''made from the Algorithm 10'''\n",
    "    hasChanged = True\n",
    "    while hasChanged:\n",
    "#       When hasChanged is False after the iteration\n",
    "#       All sets in biClust are unique\n",
    "        hasChanged = False\n",
    "        i = 0\n",
    "        N = len(biClust)\n",
    "#       using while loop because for i in range(1, N) would loop over a copy of \n",
    "#       1,2,...,N => 1, 2,...N' and would not change if we change N\n",
    "        while i < N:\n",
    "            bi = biClust[i]\n",
    "#           as the intersection is a symetric operation we could omit half of\n",
    "#           the comparaisons? using j = i + 1 insead of j = 0\n",
    "            j = i + 1\n",
    "            while j < N:\n",
    "#               ommiting this part as with j = i + 1 we don't enter this if statement\n",
    "#               if i == j:\n",
    "#                   j += 1\n",
    "#                   continue\n",
    "                bj = biClust[j]\n",
    "                intrscSz = bi & bj\n",
    "                if len(intrscSz) == 0:\n",
    "                    j += 1\n",
    "                elif len(intrscSz) == len(bi):\n",
    "                    # Bi⊂Bj\n",
    "                    hasChanged = True\n",
    "                    del biClust[i]\n",
    "                    N -= 1\n",
    "                elif len(intrscSz) == len(bj):\n",
    "                    # Bj⊂Bi\n",
    "                    hasChanged = True\n",
    "                    del biClust[j]\n",
    "                    N -= 1\n",
    "                else:\n",
    "                    biClust[j] = bi | bj\n",
    "                    hasChanged = True\n",
    "                    del biClust[i]\n",
    "                    N -= 1\n",
    "\n",
    "            i += 1\n",
    "\n",
    "def assignLabel(biClust, maxDT, consVctrs):\n",
    "    '''\n",
    "    8 - Assign a label to each set in BiClust to build the first consensus vector and \n",
    "    store it in a list of vectors ConsVctrs\n",
    "    * for convenience, ConsVctrs is a list of dictionaries that will be transformed later on \n",
    "    * in their corresponding consensus vectors\n",
    "    * storing {'maxDT=5|0': {1, 2, 3}, 'maxDT=5|1': {4, 5} ...\n",
    "    * instead of [0, 0, 0, 1, 1,...]\n",
    "    '''\n",
    "    temp = {}\n",
    "    for i, partition in enumerate(biClust):\n",
    "        temp['maxDT=%i|%i' % (maxDT,i)] = partition\n",
    "    consVctrs.append(temp)\n",
    "\n",
    "def jaccard(x, y):\n",
    "    '''\n",
    "    x and y are two dictionaries containing sets\n",
    "    returns the jaccard_score (|x∩y|/|x∪y|)\n",
    "    '''\n",
    "    xSet = [frozenset(x[key]) for key in x]        \n",
    "    ySet = [frozenset(y[key]) for key in y]\n",
    "    smallerOrEqualSet, biggerOrEqualSet = (xSet, ySet) if len(xSet) < len(ySet) else (ySet, xSet)\n",
    "    unionSet = set()\n",
    "    intersectionSet = set()\n",
    "    for i in range(0, len(biggerOrEqualSet)):\n",
    "        unionSet.add(biggerOrEqualSet[i])\n",
    "        if i < len(smallerOrEqualSet):\n",
    "            unionSet.add(biggerOrEqualSet[i] | smallerOrEqualSet[i])\n",
    "            intersectionSet.add(biggerOrEqualSet[i] & smallerOrEqualSet[i])\n",
    "    return len(intersectionSet) / len(unionSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiCons - part after FCP are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stability=1 similarity=0.002712 k=44 repartition={'maxDT=6|0': {555008, 600073, 2241036, 625684, 122392, 2156058, 556587, 2433069, 625714, 1763378, 553021, 29764, 342089, 598113, 625782, 29820, 572036, 634500, 608904, 502929, 623250, 633493, 40604, 631455, 324257, 491170, 242858, 588460, 588473, 575166, 502465, 550092, 515278, 556246, 2134237, 622302, 582879, 2692327, 569080, 634618, 556295, 576780, 613133, 2087182, 601872, 568084, 2602264, 625953, 634157, 2258228, 523061, 626501, 607052, 615246, 630606, 129878, 611176, 2239848, 269676, 473965, 1997164, 383347, 628086, 571776, 363906, 1750405, 577414, 509839, 625552, 631699, 600987, 576413, 633256, 557995, 580525, 628663, 602042, 594371, 630211, 2131908, 612814, 634853, 627691, 117232, 2486769, 285170, 578034, 548854, 1891323}, 'maxDT=6|1': {585093, 615437, 565399, 407453, 124193, 515107, 206245, 160300, 236205, 625453, 2109119, 539328, 319042, 622787, 329673, 618571, 609229, 629710, 478550, 554205, 180976, 1753458}, 'maxDT=6|2': {624134, 626183, 2298895, 612882, 107028, 472087, 592939, 532531, 633395, 300611, 523335, 2641486, 571992, 490081, 471657, 330862, 557172, 629890, 601731, 606350, 634512, 571025, 577686, 554141, 370336, 582827, 625838, 629936, 518862, 509649, 622804, 530650, 2659556, 366310, 586473, 623347, 198902, 608504, 573696, 610577, 612119, 467230, 116518, 64296, 177967, 344367, 465719, 381240, 155963, 178496, 608577, 425287, 310088, 84299, 436058, 515936, 512353, 585057, 623456, 622948, 165733, 563046, 630635, 2652523, 634744, 616831, 614804, 2503063, 620440, 597403, 548764, 431014, 634279, 551856, 315322, 155067, 126395, 543678, 543170, 624591, 514000, 295893, 536536, 582108, 633310, 49119, 245217, 233444, 488431, 133104, 608753, 632312, 420345}, 'maxDT=6|3': {619870}, 'maxDT=6|4': {2598913, 576516, 587911, 630152, 562825, 374028, 574221, 336398, 540686, 576782, 583052, 630157, 1894419, 445972, 283798, 396825, 628506, 628383, 630047, 548386, 635043, 169380, 624164, 556584, 626862, 420528, 625841, 631216, 617781, 626614, 619447, 485944, 630585, 634040, 1694780, 596157, 342974, 523710, 623421, 627136, 528066, 634433, 234311, 606665, 2513997, 255310, 526927, 315728, 282193, 565838, 2639310, 603477, 617942, 566871, 1561431, 296411, 527964, 551902, 620897, 583906, 1969407, 1073766, 631655, 482280, 1906919, 632554, 2607849, 584940, 560494, 167791, 630896, 466289, 205425, 168178, 244977, 268018, 516726, 536435, 599542, 2236538, 630012, 613501, 584191}, 'maxDT=6|5': {587906, 631044, 587783, 476937, 247819, 353804, 284812, 46605, 403085, 513934, 520588, 578958, 2548877, 1922200, 2556060, 548509, 593823, 2623263, 548261, 566310, 1691815, 949548, 631473, 585397, 560311, 388538, 595514, 592961, 548677, 634570, 1781834, 634578, 545747, 1440467, 205398, 1888343, 2063578, 2064873, 536170, 594157, 623732, 573558, 571129}, 'maxDT=6|6': {537603, 606724, 605703, 603791, 261265, 348050, 432278, 529434, 431386, 604571, 610718, 630825, 634671, 487629, 552913, 118098, 596947, 626516, 631122, 2613331, 559706, 635109, 368876, 634349, 610287, 633460, 600181, 412284}, 'maxDT=6|7': {70381}, 'maxDT=6|8': {612644, 590762, 356274, 560114, 347764, 532020, 617331, 364920, 521051, 576191}, 'maxDT=6|9': {600335, 609045, 602398, 2698535, 338731, 627253, 615229, 501443, 628293, 574283, 626763, 610391, 579550, 430686, 2564711, 261615, 289009, 620148, 500597, 479607, 596731, 406908, 627711}, 'maxDT=6|10': {1951080, 2178929, 604164, 278861}, 'maxDT=6|11': {619014, 595847, 533004, 349069, 516238, 553741, 566670, 468753, 94484, 528023, 178072, 593305, 466714, 413083, 526235, 595356, 602269, 631583, 2631703, 108834, 285475, 363939, 519589, 500006, 578850, 378920, 613417, 633637, 2617635, 627374, 391343, 465843, 200372, 498741, 626998, 618679, 627635, 228153, 611260, 629694, 629696, 612673, 634816, 536261, 69703, 630471, 632135, 2421961, 595659, 484174, 555604, 446295, 495320, 621401, 631770, 490587, 592093, 572382, 385120, 542050, 593123, 559977, 603498, 606828, 626930, 547571, 522484, 628090, 593787}, 'maxDT=6|12': {429065, 577035, 591375, 602133, 2410519, 558616, 526876, 591388, 1924641, 1268772, 1715237, 629798, 2588201, 631850, 2494507, 588846, 105523, 593972, 551478, 600632, 522312, 131145, 611402, 410699, 236620, 593995, 625740, 592976, 521297, 502868, 613461, 591958, 602718, 2581603, 394341, 620646, 629862, 561774, 201327, 135792, 618096, 588402, 635515, 594044, 630912, 529025, 1671811, 539784, 601224, 632459, 634507, 424082, 627348, 572570, 635034, 631453, 625822, 2187422, 480929, 135330, 345256, 614059, 585900, 509102, 1442991, 301232, 630449, 625330, 592051, 529078, 189624, 75454, 515774, 281801, 551115, 543948, 593103, 561363, 603859, 627933, 632546, 1591013, 1632487, 537322, 609515, 620266, 624875, 532718, 585455, 1095916, 543475, 2609908, 391419, 1187586, 206599, 407818, 632074, 632313, 610575, 569108, 592151, 992544, 2134304, 490282, 598321, 599857, 610099, 634167, 624441, 311616, 609602, 625476, 62278, 355143, 523079, 630086, 541003, 620876, 445777, 544594, 620369, 1038161, 351577, 162650, 544090, 408413, 601949, 633695, 524128, 604517, 634216, 634217, 609645, 363374, 600945, 925553, 2471283, 625527, 583032, 532859, 532350, 2567038, 2147713, 145282, 434562, 588676, 625028, 592775, 592776, 616334, 572303, 561559, 527771, 630178, 253859, 631715, 172965, 1930146, 505767, 471979, 629164, 342957, 633270, 516024, 2238904, 126394, 515515, 2171834, 2047421, 613310, 485312, 1311171, 2056643, 582087, 617416, 623562, 1678800, 2211797, 605144, 2391004, 2658268, 264159, 575967, 374756, 515046, 1115623, 401903, 615407, 1672690, 623605, 605688, 623609, 602107, 151549, 569342}, 'maxDT=6|13': {634241, 193163, 438796, 42638, 521614, 579343, 507034, 559770, 502554, 1534494, 633250, 410407, 619303, 984619, 585393, 622386, 204725, 625077, 560951, 357176, 632506, 622652, 1568828, 316227, 544839, 420935, 423879, 489929, 625745, 917586, 547287, 621656, 2545113, 512475, 631772, 445917, 577245, 624483, 526564, 1493739, 595182, 170864, 588274, 575733, 595189, 633722}, 'maxDT=6|14': {573440, 478212, 629766, 535047, 613387, 589327, 595986, 525332, 629270, 626714, 300059, 417820, 590877, 627747, 595492, 631334, 490024, 549928, 633384, 634414, 502833, 604723, 623667, 559157, 537654, 596035, 328261, 394311, 440905, 600142, 234068, 603222, 554583, 574551, 607835, 524386, 79461, 563819, 2686578, 2616950, 528892, 535682, 507523, 592007, 588430, 82575, 618129, 398487, 566428, 588956, 383140, 623780, 490662, 585383, 511657, 618665, 474283, 338604, 503469, 480943, 593071, 543924, 383158, 612023, 627386, 627387, 2603195, 626877, 179904, 571595, 2555596, 123598, 608464, 305876, 608472, 626906, 518363, 595164, 491742, 573662, 491232, 599263, 510694, 544490, 599275, 250092, 588524, 611062, 590072, 548602, 632571, 2016517, 538887, 404239, 594193, 545045, 632597, 622368, 241955, 631075, 582950, 627500, 632111, 625975, 418623, 371526, 594246, 595797, 599893, 607061, 629081, 480604, 628575, 492900, 230761, 554870, 227192, 627066, 498043, 353660, 309118, 2171264, 2289032, 516496, 586132, 607636, 617365, 1930644, 550812, 580511, 609192, 365993, 563631, 2644404, 558518, 497080, 482745, 588219, 600509, 573377, 592842, 483275, 545740, 498138, 572891, 2410459, 585695, 518116, 581614, 604655, 572401, 633330, 608243, 424950, 606206, 530936, 507388, 465406}, 'maxDT=6|15': {623738, 1673876, 625614, 618606}, 'maxDT=6|16': {1644328, 134025}, 'maxDT=6|17': {505520, 630573, 628565}, 'maxDT=6|18': {541184, 556042, 592407, 626712, 632856, 534047, 183331, 602150, 614952, 534074, 582723, 583238, 2066504, 386121, 442954, 556109, 290382, 2110039, 2375259, 2213982, 630888, 631925, 305783, 570488, 618619, 624765, 557700, 59541, 1945240, 418971, 634523, 635041, 244902, 586921, 623786, 281261, 588464, 633527, 543417, 353979, 2008262, 591566, 2478799, 581328, 575703, 469732, 595685, 330994, 2389754, 2602235, 630531, 441606, 578823, 172301, 625950, 2621734, 559912, 467753, 632114, 408371, 266040, 622398, 620356, 614733, 421712, 625517, 610158, 2681198, 572279, 580477, 232833, 630657, 566664, 40333, 505235, 633240, 1668504, 589722, 633243, 2558365, 493988, 627636, 203707, 601021, 409540, 2142662, 116174, 484305, 624593, 357851, 2202076, 627168, 556521, 486378, 496108, 550893, 608750}, 'maxDT=6|19': {600547}, 'maxDT=6|20': {594199}, 'maxDT=6|21': {570377, 625423, 629906, 2252437, 1551895, 618279, 2436400, 74290, 620215, 490297, 119353, 575545, 629692, 153788, 627520, 609489, 464724, 2564333, 633455, 565883, 605180}, 'maxDT=6|22': {464236, 492357}, 'maxDT=6|23': {119729, 591738}, 'maxDT=6|24': {475556, 556709, 591655, 475149, 386189, 529073, 300594, 577427, 628725, 526073, 632889}, 'maxDT=6|25': {2032058}, 'maxDT=6|26': {571233, 510914, 632691}, 'maxDT=6|27': {581123}, 'maxDT=6|28': {1769985, 1780737, 506380, 629773, 256532, 544791, 191000, 595992, 1877015, 471580, 2030117, 624126, 438313, 2615849, 612397, 625207, 633913, 598074, 574523, 625213, 584771, 487494, 589894, 372812, 516685, 602703, 580689, 2367058, 532565, 50263, 601175, 621655, 242778, 239707, 501339, 633432, 132191, 45664, 2473058, 531047, 551528, 609383, 627307, 412268, 465517, 587884, 628846, 581744, 580722, 70771, 289397, 469113, 590974, 625790, 594052, 552590, 628366, 560784, 1896088, 601757, 2327710, 561823, 480928, 580768, 266915, 255140, 362661, 446628, 308391, 490665, 609450, 356523, 603832, 1678014, 400063, 594111, 335553, 530113, 627907, 574663, 634057, 628938, 419536, 586962, 528083, 544467, 606930, 585433, 147675, 573153, 552166, 856294, 604906, 573166, 600814, 633071, 626417, 234740, 416500, 630005, 571128, 579321, 406265, 585464, 629500, 563967, 529153, 631051, 579340, 100621, 626444, 490768, 1541906, 2096918, 586526, 590626, 579372, 628527, 585011, 632637, 266558, 533311, 634176, 2661696, 632134, 620376, 397149, 588125, 599902, 555368, 600938, 618861, 197486, 569712, 634737, 587122, 597363, 633716, 439669, 556918, 620918, 629628, 376701, 126337, 608130, 592259, 608643, 599942, 558471, 2188680, 2488713, 584077, 1462676, 395164, 588710, 602030, 606127, 555953, 620977, 522682, 612287, 483267, 2329539, 80329, 585681, 505815, 616407, 602585, 564700, 500189, 260062, 554470, 523239, 471018, 592876, 470002, 628214, 1774071, 83453, 619006}, 'maxDT=6|29': {632107}, 'maxDT=6|30': {2044299, 245494}, 'maxDT=6|31': {627784, 592609, 360547, 603639}, 'maxDT=6|32': {503872, 609025, 2569090, 2577091, 441540, 512582, 590961, 1848820, 528021, 586716, 131933, 600094}, 'maxDT=6|33': {440323, 632836, 2668550, 379406, 612381, 548383, 170025, 570410, 2418732, 357942, 1416784, 570967, 623707, 416860, 351328, 509029, 129638, 513638, 633447, 1937511, 2569834, 484464, 574580, 631929, 429185, 1307784, 1560205, 624782, 631981, 129198, 424112, 571571, 555706, 623290, 586436, 627399, 66254, 632017, 2677969, 1911513, 632037, 627435, 2113778, 472309, 504057, 584446, 481024, 478977, 575745, 549636, 630540, 2451726, 1739026, 2347802, 1106724, 494389, 336695, 624445, 406337, 558914, 447306, 392526, 633679, 615249, 2498388, 260949, 421209, 574817, 551267, 465764, 559469, 51576, 539514, 521601, 626055, 600975, 401296, 578450, 613280, 1468838, 418224, 630200, 628157, 553410, 2621379, 617925, 554951, 625108, 1942999, 627160, 625128, 578541, 57340, 626173, 348159}, 'maxDT=6|34': {633857, 517999, 623797, 142935, 576475}, 'maxDT=6|35': {571365, 614345, 585769, 2341839, 2517778, 629560, 571389}, 'maxDT=6|36': {627947}, 'maxDT=6|37': {514186, 388750, 2139037, 592158, 95906, 1951139, 2447528, 626857, 580779, 624127, 553655, 361410, 2433221, 606282, 107339, 476108, 630730, 605266, 589525, 630613, 633178, 506206, 578655, 485604, 2146277, 581611, 606444, 629613, 546675, 625014, 570872, 251385, 509183}, 'maxDT=6|38': {152962, 605571, 2147620, 635416, 385387, 383372, 598860, 623052, 2522932, 547413, 633112, 624060, 614844, 2526493, 493822}, 'maxDT=6|39': {595781, 587621, 507671, 432718, 607927}, 'maxDT=6|40': {523271, 479753, 537622, 573462, 86047, 359460, 552498, 537658, 574529, 566872, 629342, 546400, 564325, 1841267, 508025, 547986, 320153, 632486, 607411, 314555, 476868, 359114, 526547, 485594, 124124, 1087710, 262391, 631038, 570113, 28418, 573697, 591619, 410886, 573197, 165647, 440591, 83219, 602913, 483108, 374055, 354607, 2384687, 1619251, 279868, 632641, 491843, 539971, 632133, 618824, 483666, 366424, 596321, 152428, 267118, 574830, 600436, 69494, 614263, 519544, 171896, 325497, 632190, 599937, 2343809, 617348, 406937, 562585, 625574, 596903, 227752, 566185, 620974, 566704, 484787, 2358707, 467894, 625078, 2446778, 387009, 620485, 596432, 291805, 577502, 383971, 627176, 552441, 128510}, 'maxDT=6|41': {553394, 547332, 570514}, 'maxDT=6|42': {537606, 524295, 618002, 572438, 583192, 628771, 627750, 187435, 312886, 2488382, 549951, 590914, 632900, 626252, 614477, 589390, 633942, 524378, 410203, 1855583, 412258, 426610, 510070, 615031, 426616, 2049668, 598662, 474759, 622215, 633998, 627343, 550545, 622773, 520377, 358075, 397506, 577236, 2620636, 634589, 362223, 568047, 613116, 469761, 1947911, 569609, 634128, 490769, 562450, 602902, 634649, 335648, 588590, 191797, 485374, 556858, 628029, 553280, 604997, 494919, 624970, 344396, 575824, 1470291, 2454878, 1100639, 576383, 2529663, 175490, 551304, 477067, 617355, 501652, 599958, 629654, 608152, 628122, 419233, 588707, 597926, 2680742, 2419115, 416689, 572854, 2665399, 566715, 633281, 601550, 2697181, 608735, 381927, 246248, 585709, 634862, 511473, 189428, 633341, 634878}, 'maxDT=6|43': {2629436, 525832, 475945, 231339, 2088765, 578189, 75728, 166160, 527826, 620368, 1270832, 1474869, 298040, 1876636, 363773, 351775}} \n",
      "stability=1 similarity=0.006688 k=7 repartition={'maxDT=5|0': {505520, 630573, 628565}, 'maxDT=5|1': {523271, 479753, 537622, 573462, 86047, 359460, 552498, 537658, 574529, 566872, 629342, 546400, 564325, 1841267, 508025, 547986, 320153, 632486, 607411, 314555, 476868, 359114, 526547, 485594, 124124, 1087710, 262391, 631038, 570113, 28418, 573697, 591619, 410886, 573197, 165647, 440591, 83219, 602913, 483108, 374055, 354607, 2384687, 1619251, 279868, 632641, 491843, 539971, 632133, 618824, 483666, 366424, 596321, 152428, 267118, 574830, 600436, 69494, 614263, 519544, 171896, 325497, 632190, 599937, 2343809, 617348, 406937, 562585, 625574, 596903, 227752, 566185, 620974, 566704, 484787, 2358707, 467894, 625078, 2446778, 387009, 620485, 596432, 291805, 577502, 383971, 627176, 552441, 128510}, 'maxDT=5|2': {600335, 609045, 602398, 2698535, 338731, 627253, 615229, 501443, 628293, 574283, 626763, 610391, 619870, 579550, 430686, 2564711, 261615, 289009, 620148, 500597, 479607, 596731, 406908, 627711}, 'maxDT=5|3': {2598913, 576516, 587783, 429065, 247819, 540686, 1894419, 602133, 2410519, 1268772, 1715237, 629798, 566310, 631850, 2494507, 588846, 105523, 593972, 622652, 1568828, 1694780, 592961, 544839, 522312, 131145, 420935, 593995, 611402, 410699, 236620, 625740, 2513997, 592976, 917586, 521297, 625745, 502868, 591958, 613461, 621656, 1888343, 2581603, 394341, 620646, 629862, 630896, 623732, 573558, 2236538, 594044, 613501, 630912, 587906, 587911, 539784, 601224, 284812, 2548877, 424082, 283798, 1922200, 635034, 507034, 572570, 2556060, 2187422, 625822, 135330, 635043, 1691815, 345256, 585900, 626862, 509102, 301232, 1442991, 625841, 592051, 560311, 189624, 634040, 596157, 281801, 551115, 543948, 593103, 561363, 2063578, 627933, 583906, 526564, 1632487, 1906919, 624875, 1095916, 609515, 532718, 584940, 595182, 244977, 168178, 594157, 575733, 595189, 391419, 630012, 1969407, 631044, 407818, 632074, 374028, 576782, 610575, 592151, 630047, 2134304, 992544, 949548, 598321, 617781, 634167, 311616, 609602, 630086, 541003, 620876, 255310, 315728, 445777, 603477, 351577, 544090, 620897, 604517, 634216, 634217, 609645, 560494, 466289, 2471283, 583032, 532859, 634241, 434562, 2147713, 625028, 630152, 583052, 630157, 521614, 520588, 578958, 561559, 527771, 633250, 630178, 169380, 548261, 629164, 631216, 625077, 633270, 2238904, 126394, 515515, 388538, 2047421, 523710, 627136, 1311171, 2056643, 582087, 489929, 606665, 2639310, 1678800, 617942, 547287, 2545113, 512475, 296411, 445917, 575967, 1115623, 2064873, 401903, 588274, 1672690, 599542, 605688, 632313, 584191, 577035, 438796, 353804, 336398, 591375, 46605, 445972, 558616, 396825, 526876, 591388, 1534494, 1924641, 548386, 624164, 556584, 2588201, 984619, 551478, 600632, 485944, 595514, 634433, 565838, 526927, 282193, 205398, 566871, 527964, 602718, 1073766, 536170, 561774, 201327, 135792, 205425, 588402, 618096, 516726, 635515, 529025, 1671811, 562825, 193163, 632459, 634507, 42638, 403085, 627348, 559770, 631453, 548509, 628383, 480929, 614059, 420528, 585393, 625330, 630449, 631473, 585397, 529078, 632506, 75454, 515774, 528066, 634570, 634578, 603859, 1440467, 577245, 632546, 1591013, 2607849, 537322, 1493739, 620266, 632554, 585455, 268018, 543475, 2609908, 1781834, 571129, 1187586, 206599, 476937, 574221, 579343, 569108, 502554, 628506, 2623263, 410407, 619303, 490282, 599857, 622386, 610099, 560951, 357176, 624441, 630585, 623421, 316227, 625476, 548677, 62278, 355143, 523079, 234311, 620369, 544594, 1038161, 1561431, 162650, 408413, 601949, 633695, 524128, 624483, 631655, 363374, 167791, 170864, 600945, 925553, 536435, 625527, 633722, 2567038, 532350, 145282, 588676, 592775, 592776, 616334, 572303, 513934, 593823, 1930146, 631715, 253859, 172965, 505767, 471979, 342957, 204725, 626614, 619447, 516024, 2171834, 613310, 342974, 485312, 423879, 617416, 623562, 545747, 2211797, 605144, 631772, 2391004, 551902, 2658268, 264159, 374756, 515046, 482280, 615407, 623605, 623609, 602107, 151549, 569342}, 'maxDT=5|4': {555008, 573440, 600073, 595986, 626714, 417820, 630825, 2433069, 1763378, 532531, 559157, 553021, 596035, 342089, 618571, 600142, 2613331, 598113, 524386, 557172, 600181, 592007, 606350, 577686, 565399, 432278, 383140, 618665, 383158, 2603195, 626877, 622787, 571595, 487629, 608464, 622804, 608472, 530650, 626906, 518363, 2134237, 491742, 573662, 635109, 368876, 250092, 198902, 608504, 590072, 573696, 538887, 2087182, 610577, 594193, 545045, 467230, 241955, 612644, 631075, 344367, 381240, 155963, 178496, 608577, 594246, 84299, 631122, 629081, 512353, 622948, 2652523, 1997164, 1753458, 383347, 364920, 627066, 498043, 616831, 571776, 2171264, 516496, 614804, 586132, 2503063, 604571, 610718, 633256, 563631, 2644404, 588219, 600509, 543170, 594371, 612814, 498138, 582108, 633310, 604655, 117232, 2486769, 285170, 578034, 608753, 633330, 530936, 420345, 528892, 465406, 606724, 535047, 2241036, 612882, 107028, 629270, 631334, 490024, 633384, 160300, 633395, 604723, 328261, 440905, 234068, 571992, 559706, 490081, 471657, 563819, 633460, 412284, 572036, 608904, 588430, 82575, 623250, 633493, 631455, 324257, 588460, 236205, 338604, 588473, 627386, 627387, 576191, 539328, 502465, 518862, 123598, 305876, 510694, 586473, 588524, 70381, 180976, 623347, 611062, 613133, 404239, 568084, 64296, 627500, 625453, 523061, 465719, 418623, 371526, 310088, 607052, 615246, 607061, 129878, 521051, 623456, 611176, 473965, 617331, 625552, 631699, 617365, 600987, 576413, 580511, 431014, 609192, 590762, 557995, 580525, 551856, 543678, 592842, 545740, 609229, 629710, 596947, 295893, 627691, 488431, 572401, 560114, 424950, 1891323, 537603, 478212, 629766, 613387, 615437, 2298895, 625684, 525332, 472087, 529434, 300059, 590877, 515107, 627747, 549928, 592939, 502833, 625714, 623667, 537654, 29764, 523335, 394311, 603222, 574551, 330862, 625782, 29820, 629890, 535682, 502929, 261265, 398487, 566428, 554141, 588956, 623780, 490662, 242858, 582827, 474283, 625838, 593071, 629936, 543924, 550092, 515278, 556246, 595164, 554205, 582879, 599263, 2659556, 2692327, 599275, 2016517, 556295, 576780, 2602264, 431386, 124193, 625953, 582950, 634157, 632111, 2258228, 625975, 425287, 118098, 478550, 480604, 585057, 492900, 2239848, 230761, 269676, 628086, 353660, 363906, 585093, 1750405, 2289032, 607636, 1930644, 597403, 206245, 634279, 365993, 558518, 497080, 482745, 155067, 126395, 630211, 572891, 245217, 634349, 632312, 507388, 624134, 626183, 605703, 589327, 122392, 2156058, 595492, 556587, 634414, 532020, 319042, 300611, 2641486, 554583, 607835, 79461, 2686578, 347764, 2616950, 601731, 634500, 507523, 603791, 634512, 571025, 618129, 40604, 370336, 491170, 585383, 511657, 503469, 480943, 612023, 575166, 2109119, 179904, 2555596, 509649, 622302, 491232, 366310, 544490, 569080, 634618, 548602, 632571, 601872, 632597, 612119, 622368, 116518, 177967, 634671, 626501, 630606, 626516, 595797, 599893, 436058, 628575, 515936, 165733, 563046, 630635, 554870, 634744, 227192, 309118, 577414, 509839, 348050, 620440, 548764, 407453, 550812, 356274, 628663, 602042, 315322, 573377, 2131908, 329673, 483275, 624591, 514000, 552913, 536536, 2410459, 49119, 585695, 233444, 634853, 518116, 581614, 610287, 133104, 608243, 548854, 606206}, 'maxDT=5|5': {1780737, 1769985, 570377, 506380, 475149, 629773, 256532, 1551895, 544791, 595992, 1877015, 191000, 471580, 600094, 2030117, 438313, 2615849, 612397, 74290, 300594, 625207, 119353, 575545, 632889, 598074, 574523, 633913, 625213, 503872, 584771, 487494, 589894, 512582, 372812, 516685, 602703, 580689, 2367058, 532565, 50263, 601175, 621655, 242778, 239707, 633432, 501339, 132191, 45664, 2473058, 609383, 531047, 551528, 627307, 587884, 412268, 628846, 633455, 581744, 590961, 580722, 70771, 465517, 289397, 469113, 565883, 590974, 625790, 594052, 386189, 552590, 628366, 560784, 629906, 2252437, 528021, 1896088, 601757, 2327710, 561823, 580768, 480928, 266915, 255140, 362661, 446628, 308391, 556709, 490665, 609450, 356523, 529073, 620215, 603832, 153788, 1678014, 594111, 400063, 335553, 530113, 627907, 441540, 2577091, 574663, 634057, 628938, 419536, 609489, 586962, 606930, 528083, 544467, 585433, 147675, 573153, 552166, 856294, 604906, 2564333, 573166, 633071, 600814, 626417, 234740, 630005, 245494, 416500, 571128, 526073, 406265, 579321, 585464, 629500, 563967, 529153, 609025, 631051, 579340, 100621, 626444, 625423, 490768, 1541906, 2096918, 594199, 586526, 590626, 618279, 591655, 579372, 628527, 2436400, 585011, 490297, 632637, 266558, 533311, 627520, 634176, 2661696, 492357, 632134, 464724, 620376, 588125, 131933, 397149, 599902, 571233, 555368, 600938, 464236, 618861, 197486, 569712, 634737, 587122, 632691, 597363, 439669, 620918, 633716, 556918, 629628, 376701, 126337, 608130, 592259, 608643, 2569090, 599942, 558471, 2188680, 2488713, 619006, 2044299, 584077, 577427, 1462676, 395164, 475556, 588710, 602030, 606127, 620977, 555953, 2032058, 522682, 629692, 612287, 510914, 483267, 2329539, 80329, 585681, 505815, 616407, 602585, 564700, 500189, 586716, 260062, 600547, 554470, 523239, 471018, 592876, 470002, 1848820, 628725, 628214, 1774071, 605180, 83453, 624126}, 'maxDT=5|6': {633857, 440323, 632836, 2668550, 537606, 524295, 572438, 612381, 628771, 627750, 170025, 570410, 585769, 2418732, 187435, 1270832, 298040, 2488382, 549951, 590914, 632900, 606282, 614477, 605266, 633942, 524378, 623707, 416860, 578655, 351328, 1855583, 509029, 1937511, 484464, 574580, 510070, 631929, 429185, 1307784, 514186, 624782, 633998, 570514, 2447528, 626857, 580779, 631981, 129198, 424112, 571571, 623797, 622773, 520377, 397506, 2433221, 632017, 2677969, 2620636, 485604, 632037, 627947, 606444, 2113778, 472309, 504057, 363773, 493822, 509183, 575745, 1947911, 569609, 2451726, 634128, 490769, 1739026, 562450, 166160, 633112, 2526493, 592158, 2147620, 191797, 1474869, 628029, 553280, 494919, 624970, 344396, 392526, 575824, 421209, 633178, 506206, 2454878, 574817, 551267, 385387, 559469, 625014, 634878, 51576, 2529663, 521601, 175490, 152962, 605571, 626055, 551304, 383372, 628122, 419233, 1951139, 1468838, 2419115, 418224, 553394, 572854, 630200, 566715, 624060, 628157, 614844, 633281, 553410, 617925, 623052, 601550, 527826, 625108, 1942999, 627160, 608735, 625128, 246248, 511473, 570872, 251385, 633341, 626173, 624127, 547332, 525832, 379406, 618002, 583192, 635416, 548383, 351775, 357942, 312886, 626252, 589390, 1416784, 547413, 142935, 570967, 410203, 412258, 129638, 513638, 633447, 2569834, 426610, 615031, 426616, 2049668, 598662, 474759, 622215, 1560205, 388750, 627343, 578189, 550545, 1876636, 95906, 553655, 555706, 623290, 358075, 586436, 627399, 66254, 577236, 589525, 1911513, 634589, 627435, 362223, 568047, 613116, 584446, 481024, 478977, 469761, 549636, 630540, 2517778, 602902, 634649, 2347802, 335648, 1106724, 475945, 588590, 2522932, 494389, 336695, 629560, 556858, 2629436, 624445, 2088765, 406337, 558914, 604997, 447306, 107339, 598860, 633679, 620368, 615249, 1470291, 2498388, 260949, 630613, 1100639, 465764, 629613, 517999, 546675, 539514, 576383, 477067, 617355, 600975, 401296, 578450, 501652, 599958, 629654, 608152, 2139037, 613280, 588707, 597926, 2680742, 231339, 416689, 2665399, 361410, 2621379, 554951, 614345, 630730, 476108, 2341839, 75728, 576475, 2697181, 571365, 2146277, 381927, 581611, 578541, 585709, 634862, 189428, 57340, 571389, 485374, 348159}} \n",
      "stability=1 similarity=0.046287 k=4 repartition={'maxDT=4|0': {633857, 440323, 632836, 2668550, 537606, 524295, 523271, 572438, 537622, 573462, 612381, 86047, 628771, 359460, 627750, 170025, 570410, 585769, 2418732, 187435, 1270832, 298040, 537658, 2488382, 549951, 574529, 590914, 632900, 606282, 614477, 605266, 633942, 524378, 623707, 416860, 578655, 351328, 1855583, 509029, 564325, 1937511, 484464, 1841267, 574580, 510070, 631929, 508025, 429185, 1307784, 514186, 624782, 633998, 570514, 547986, 2447528, 626857, 580779, 631981, 129198, 424112, 571571, 607411, 623797, 622773, 520377, 314555, 397506, 2433221, 632017, 2677969, 526547, 485594, 2620636, 124124, 1087710, 485604, 632037, 627947, 606444, 2113778, 472309, 262391, 504057, 363773, 493822, 509183, 631038, 575745, 573697, 410886, 1947911, 569609, 2451726, 440591, 634128, 490769, 1739026, 562450, 166160, 83219, 633112, 2526493, 592158, 2147620, 374055, 354607, 1619251, 191797, 1474869, 279868, 628029, 553280, 491843, 539971, 632133, 494919, 618824, 624970, 344396, 392526, 575824, 483666, 421209, 633178, 506206, 2454878, 574817, 596321, 551267, 385387, 559469, 574830, 600436, 625014, 634878, 51576, 519544, 632190, 2529663, 521601, 175490, 152962, 605571, 626055, 551304, 383372, 406937, 628122, 562585, 419233, 1951139, 1468838, 227752, 2419115, 620974, 418224, 566704, 553394, 484787, 2358707, 572854, 625078, 630200, 2446778, 566715, 624060, 628157, 614844, 633281, 553410, 617925, 623052, 601550, 596432, 527826, 625108, 1942999, 627160, 608735, 625128, 246248, 627176, 511473, 570872, 251385, 552441, 633341, 626173, 624127, 128510, 547332, 525832, 479753, 379406, 618002, 583192, 635416, 548383, 351775, 552498, 357942, 312886, 626252, 589390, 432718, 1416784, 547413, 142935, 570967, 566872, 410203, 629342, 546400, 412258, 129638, 513638, 633447, 2569834, 426610, 615031, 426616, 2049668, 598662, 474759, 622215, 1560205, 388750, 627343, 578189, 550545, 320153, 1876636, 95906, 632486, 553655, 607927, 555706, 623290, 358075, 586436, 476868, 627399, 359114, 66254, 577236, 589525, 1911513, 634589, 627435, 362223, 568047, 613116, 584446, 481024, 478977, 469761, 28418, 549636, 570113, 591619, 630540, 573197, 165647, 2517778, 602902, 507671, 634649, 2347802, 335648, 602913, 1106724, 483108, 475945, 588590, 2384687, 2522932, 494389, 336695, 629560, 556858, 2629436, 624445, 2088765, 406337, 558914, 632641, 604997, 595781, 447306, 107339, 598860, 633679, 620368, 615249, 1470291, 2498388, 260949, 630613, 366424, 1100639, 465764, 587621, 152428, 629613, 267118, 517999, 546675, 69494, 614263, 171896, 325497, 539514, 576383, 599937, 2343809, 617348, 477067, 617355, 600975, 401296, 578450, 501652, 599958, 629654, 608152, 2139037, 613280, 588707, 597926, 2680742, 596903, 566185, 625574, 231339, 416689, 467894, 2665399, 387009, 361410, 2621379, 620485, 554951, 614345, 630730, 476108, 2341839, 75728, 576475, 2697181, 291805, 577502, 383971, 571365, 2146277, 381927, 581611, 578541, 585709, 634862, 189428, 57340, 571389, 485374, 348159}, 'maxDT=4|1': {585093, 615437, 1673876, 565399, 407453, 124193, 515107, 206245, 160300, 236205, 625453, 2109119, 539328, 319042, 622787, 329673, 618571, 609229, 625614, 629710, 478550, 554205, 618606, 180976, 1753458, 623738}, 'maxDT=4|2': {475149, 544791, 595992, 626712, 632856, 600094, 602150, 438313, 612397, 532531, 575545, 632889, 598074, 622652, 1568828, 503872, 487494, 589894, 2066504, 544839, 372812, 917586, 532565, 239707, 2213982, 630888, 587884, 628846, 581744, 557172, 469113, 618619, 624765, 594052, 606350, 59541, 577686, 635041, 446628, 362661, 356523, 153788, 594111, 628938, 622804, 575703, 530650, 147675, 526564, 856294, 2564333, 633071, 575733, 198902, 608504, 573696, 631051, 100621, 172301, 610577, 594199, 467230, 2621734, 344367, 381240, 155963, 266558, 178496, 608577, 84299, 614733, 588125, 512353, 622948, 555368, 2652523, 618861, 2681198, 569712, 620918, 616831, 592259, 608643, 2488713, 2044299, 584077, 1462676, 614804, 2503063, 633240, 633243, 2558365, 633250, 475556, 493988, 620977, 625077, 2032058, 522682, 543170, 2142662, 80329, 489929, 547287, 602585, 512475, 2202076, 500189, 582108, 633310, 627168, 600547, 496108, 608750, 608753, 588274, 1774071, 420345, 619006, 541184, 1769985, 506380, 438796, 612882, 256532, 107028, 592407, 191000, 471580, 1534494, 2030117, 614952, 2615849, 74290, 633395, 625207, 119353, 625213, 512582, 442954, 516685, 602703, 2110039, 633432, 571992, 45664, 490081, 531047, 551528, 471657, 627307, 412268, 465517, 633455, 289397, 305783, 565883, 557700, 193163, 559770, 561823, 266915, 281261, 588464, 529073, 633527, 543417, 1678014, 400063, 2577091, 518862, 2478799, 606930, 469732, 586473, 604906, 1493739, 600814, 623347, 416500, 406265, 629500, 563967, 529153, 609025, 625423, 502554, 586526, 590626, 410407, 559912, 467753, 64296, 619303, 408371, 465719, 357176, 490297, 533311, 627520, 316227, 492357, 310088, 131933, 623456, 600938, 625517, 197486, 170864, 633716, 572279, 633722, 629628, 580477, 2569090, 134025, 588710, 431014, 551856, 555953, 119729, 627636, 203707, 629692, 601021, 543678, 510914, 2329539, 484305, 295893, 586716, 631772, 523239, 486378, 592876, 488431, 470002, 605180, 1780737, 570377, 556042, 629773, 2298895, 1877015, 472087, 183331, 592939, 633913, 574523, 584771, 582723, 523335, 420935, 386121, 556109, 580689, 625745, 50263, 601175, 621655, 242778, 621656, 132191, 2473058, 609383, 330862, 590961, 580722, 70771, 631925, 570488, 590974, 625790, 629890, 386189, 629906, 507034, 418971, 554141, 2327710, 580768, 255140, 244902, 308391, 490665, 609450, 586921, 623786, 582827, 625838, 629936, 627907, 441540, 2008262, 574663, 634057, 609489, 586962, 2659556, 552166, 595182, 330994, 234740, 630005, 595189, 2602235, 441606, 578823, 490768, 625950, 2436400, 632114, 585011, 634176, 2661696, 632134, 425287, 585057, 464236, 587122, 597363, 439669, 126337, 232833, 634241, 558471, 2188680, 566664, 40333, 521614, 505235, 1668504, 597403, 634279, 155067, 126395, 116174, 2545113, 357851, 564700, 445917, 245217, 554470, 556521, 1848820, 628214, 632312, 83453, 624126, 624134, 626183, 1551895, 534047, 984619, 300594, 534074, 300611, 583238, 290382, 2641486, 2367058, 501339, 2375259, 601731, 552590, 628366, 560784, 634512, 571025, 42638, 2252437, 528021, 1896088, 1945240, 634523, 601757, 480928, 370336, 556709, 505520, 585393, 620215, 603832, 632506, 353979, 335553, 530113, 591566, 419536, 581328, 509649, 528083, 544467, 585433, 577245, 573153, 595685, 366310, 573166, 626417, 245494, 571128, 526073, 579321, 585464, 2389754, 630531, 579340, 626444, 579343, 1541906, 2096918, 612119, 116518, 618279, 591655, 1644328, 579372, 630573, 628527, 177967, 622386, 560951, 266040, 632637, 622398, 620356, 421712, 464724, 628565, 620376, 436058, 397149, 599902, 515936, 571233, 624483, 165733, 563046, 630635, 610158, 634737, 632691, 556918, 634744, 591738, 376701, 630657, 608130, 599942, 577427, 620440, 589722, 395164, 548764, 602030, 606127, 204725, 315322, 612287, 483267, 409540, 423879, 624591, 514000, 585681, 624593, 505815, 616407, 536536, 260062, 49119, 233444, 471018, 550893, 133104, 628725}, 'maxDT=4|3': {573440, 478212, 629766, 535047, 613387, 589327, 595986, 525332, 629270, 626714, 300059, 417820, 590877, 627747, 595492, 631334, 490024, 549928, 633384, 634414, 502833, 604723, 623667, 559157, 537654, 596035, 328261, 394311, 627784, 440905, 600142, 234068, 603222, 554583, 574551, 607835, 524386, 360547, 79461, 563819, 2686578, 2616950, 528892, 535682, 507523, 592007, 588430, 82575, 618129, 398487, 566428, 588956, 383140, 623780, 490662, 585383, 511657, 618665, 474283, 338604, 503469, 480943, 593071, 543924, 383158, 612023, 627386, 627387, 2603195, 626877, 179904, 571595, 2555596, 123598, 608464, 305876, 608472, 626906, 518363, 595164, 491742, 573662, 491232, 592609, 599263, 510694, 544490, 599275, 250092, 588524, 611062, 590072, 548602, 632571, 2016517, 538887, 404239, 594193, 545045, 632597, 622368, 241955, 631075, 582950, 627500, 632111, 625975, 418623, 371526, 594246, 595797, 599893, 607061, 629081, 480604, 628575, 492900, 230761, 554870, 227192, 627066, 498043, 353660, 309118, 2171264, 2289032, 516496, 586132, 607636, 617365, 1930644, 550812, 580511, 609192, 365993, 563631, 2644404, 558518, 497080, 482745, 588219, 600509, 573377, 592842, 483275, 545740, 498138, 572891, 2410459, 585695, 518116, 581614, 604655, 572401, 633330, 608243, 424950, 603639, 530936, 606206, 507388, 465406}} \n",
      "stability=3 similarity=0.106876 k=1 repartition={'maxDT=1|0': {573440, 540686, 602133, 544791, 626714, 417820, 630825, 438313, 2494507, 2433069, 532531, 593972, 598074, 622652, 1568828, 553021, 487494, 544839, 69703, 589894, 1781834, 626763, 618571, 131145, 593995, 372812, 917586, 2613331, 532565, 610391, 1888343, 385120, 598113, 524386, 360547, 618606, 581744, 630896, 557172, 573558, 2236538, 594044, 630912, 594052, 516238, 606350, 577686, 565399, 635034, 2556060, 602269, 2187422, 135330, 635043, 446628, 1691815, 618665, 356523, 585900, 626862, 618679, 626877, 594111, 622787, 487629, 561363, 622804, 626906, 147675, 2134237, 491742, 573662, 635109, 856294, 250092, 594157, 368876, 2564333, 532718, 626930, 168178, 590072, 573696, 631044, 631051, 610575, 594193, 610577, 94484, 545045, 594199, 602398, 467230, 2134304, 241955, 631075, 2617635, 500006, 344367, 598321, 1474869, 626998, 381240, 155963, 266558, 311616, 594246, 541003, 278861, 315728, 631122, 512353, 622948, 385387, 618861, 569712, 1753458, 479607, 364920, 627066, 532859, 2171264, 434562, 2044299, 520588, 516496, 586132, 1462676, 614804, 561559, 2503063, 610718, 631216, 553394, 2032058, 614844, 627136, 594371, 1311171, 2056643, 582087, 606665, 623052, 602585, 512475, 582108, 500189, 2064873, 401903, 2486769, 578034, 1774071, 528892, 619006, 1769985, 606724, 619014, 438796, 533004, 2241036, 336398, 107028, 635416, 471580, 631334, 160300, 74290, 627253, 119353, 328261, 516685, 565838, 602703, 234068, 205398, 430686, 602718, 45664, 1073766, 2564711, 471657, 627307, 606828, 561774, 201327, 135792, 205425, 516726, 565883, 635515, 529025, 1671811, 193163, 578189, 82575, 623250, 627348, 1876636, 631453, 561823, 631455, 324257, 266915, 627374, 631473, 529078, 627386, 627387, 123598, 606930, 586473, 537322, 70381, 180976, 623347, 2609908, 611062, 406265, 529153, 553741, 574221, 586526, 631583, 590626, 410407, 619303, 475945, 627500, 357176, 615229, 623421, 418623, 533311, 627520, 316227, 492357, 62278, 234311, 574283, 607052, 598860, 484174, 615246, 607061, 1561431, 521051, 623456, 631655, 611176, 197486, 500597, 349069, 631699, 1930146, 631715, 172965, 431014, 590762, 471979, 557995, 627635, 619447, 2171834, 611260, 623562, 545740, 545747, 295893, 631770, 631772, 627691, 615407, 488431, 623605, 623609, 627711, 537603, 570377, 615437, 2298895, 525332, 1877015, 472087, 529434, 300059, 590877, 627747, 566310, 549928, 631850, 1270832, 623667, 537654, 574523, 29764, 394311, 627784, 611402, 410699, 521297, 603222, 574551, 50263, 242778, 132191, 2581603, 394341, 70771, 623732, 623738, 29820, 590974, 2548877, 570514, 283798, 398487, 1922200, 566428, 554141, 2327710, 623780, 255140, 308391, 345256, 242858, 582827, 509102, 1442991, 623797, 189624, 627907, 574663, 2421961, 550092, 586962, 595164, 554205, 627933, 599263, 582879, 2659556, 2692327, 599275, 627947, 595182, 234740, 595189, 2016517, 632074, 374028, 2602264, 431386, 992544, 124193, 578850, 2147620, 582950, 632107, 632111, 2258228, 632134, 632135, 255310, 603477, 480604, 619870, 542050, 492900, 1951080, 230761, 603498, 464236, 587122, 2471283, 439669, 628086, 569342, 583032, 628090, 406908, 353660, 2147713, 152962, 1750405, 558471, 2188680, 583052, 521614, 578958, 566670, 607636, 1930644, 595356, 169380, 206245, 365993, 558518, 497080, 624060, 2639310, 2545113, 296411, 554470, 1115623, 1672690, 628214, 603639, 599542, 632313, 632312, 83453, 624126, 624134, 525832, 353804, 46605, 591375, 558616, 2156058, 591388, 595492, 624164, 984619, 595514, 300611, 628293, 554583, 566871, 607835, 501339, 79461, 620148, 562825, 632459, 403085, 42638, 628366, 603791, 571025, 628383, 480928, 480929, 370336, 480943, 505520, 612023, 603832, 620215, 632506, 75454, 575166, 530113, 501443, 595659, 419536, 509649, 603859, 632546, 1591013, 366310, 620266, 632554, 268018, 571128, 571129, 579321, 632571, 206599, 476937, 579340, 579343, 468753, 1541906, 632597, 612119, 628506, 2623263, 116518, 579372, 628527, 177967, 599857, 624441, 632637, 620368, 620369, 1038161, 464724, 628565, 595797, 599893, 620376, 436058, 599902, 628575, 571233, 624483, 165733, 563046, 517999, 632691, 554870, 227192, 309118, 608130, 145282, 599942, 595847, 513934, 616334, 509839, 178072, 620440, 526235, 550812, 407453, 395164, 505767, 231339, 628663, 612287, 485312, 2131908, 423879, 329673, 624591, 514000, 75728, 505815, 616407, 2410459, 579550, 260062, 264159, 518116, 374756, 133104, 608243, 555008, 2598913, 604164, 587783, 600073, 247819, 595986, 1894419, 2631703, 595992, 2410519, 378920, 612397, 1763378, 559157, 575545, 596035, 522312, 342089, 600142, 591958, 239707, 620646, 587884, 628846, 600181, 469113, 587906, 592007, 587911, 284812, 424082, 432278, 383140, 362661, 391343, 301232, 592051, 383158, 2603195, 153788, 596157, 628938, 571595, 551115, 608464, 608472, 530650, 518363, 592093, 583906, 526564, 1632487, 1906919, 624875, 1095916, 633071, 289009, 522484, 575733, 198902, 608504, 391419, 493822, 538887, 407818, 100621, 2087182, 600335, 166160, 592151, 633112, 108834, 612644, 178496, 612673, 608577, 84299, 620876, 629081, 588125, 620897, 604517, 555368, 2652523, 1997164, 383347, 620918, 498043, 616831, 571776, 592259, 608643, 625028, 2488713, 383372, 584077, 604571, 633250, 633256, 629164, 563631, 620977, 2644404, 625077, 633270, 2238904, 522682, 588219, 600509, 543170, 489929, 80329, 612814, 547287, 498138, 633310, 575967, 600547, 604655, 117232, 608753, 588274, 633330, 285170, 530936, 420345, 465406, 584191, 547332, 535047, 506380, 612882, 256532, 629270, 191000, 526876, 1534494, 2030117, 490024, 633384, 2615849, 604723, 633395, 551478, 625207, 485944, 600632, 625213, 440905, 526927, 555604, 547413, 633432, 571992, 559706, 490081, 531047, 551528, 563819, 412268, 465517, 633455, 588402, 633460, 289397, 412284, 572036, 608904, 588430, 1673876, 633493, 559770, 338604, 236205, 588460, 420528, 625330, 588473, 1678014, 400063, 539328, 576191, 502465, 518862, 1440467, 305876, 592609, 510694, 2607849, 604906, 1493739, 588524, 600814, 547571, 416500, 543475, 596731, 629500, 563967, 613133, 404239, 625423, 568084, 609045, 502554, 285475, 633637, 64296, 490282, 338731, 625453, 523061, 465719, 228153, 490297, 625476, 371526, 355143, 523079, 310088, 129878, 621401, 162650, 408413, 633695, 559977, 600938, 473965, 363374, 170864, 600945, 617331, 633716, 625527, 633722, 629628, 2567038, 588676, 592775, 592776, 572303, 625552, 617365, 600987, 576413, 580511, 588710, 609192, 342957, 580525, 551856, 555953, 465843, 629692, 629694, 342974, 629696, 613310, 510914, 543678, 2329539, 617416, 592842, 609229, 625614, 629710, 596947, 605144, 576475, 2391004, 572382, 551902, 515046, 523239, 482280, 592876, 572401, 470002, 560114, 424950, 1891323, 605180, 1780737, 633857, 478212, 576516, 629766, 429065, 613387, 629773, 625684, 515107, 1268772, 1715237, 629798, 613417, 592939, 588846, 502833, 625714, 105523, 498741, 298040, 633913, 1694780, 592961, 584771, 420935, 523335, 236620, 625740, 2513997, 592976, 625745, 580689, 502868, 613461, 601175, 621656, 621655, 490587, 2473058, 629862, 609383, 330862, 580722, 625782, 613501, 625790, 535682, 629890, 539784, 601224, 261265, 629906, 502929, 507034, 572570, 588956, 625822, 580768, 490662, 490665, 609450, 474283, 625838, 593071, 629936, 625841, 543924, 560311, 634040, 634057, 281801, 543948, 515278, 593103, 609489, 556246, 2063578, 593123, 552166, 609515, 584940, 244977, 630005, 630012, 363773, 1969407, 556295, 576780, 576782, 490768, 2526493, 630047, 625953, 2698535, 949548, 634157, 2436400, 585011, 617781, 625975, 634167, 634176, 2661696, 609602, 630086, 425287, 445777, 118098, 478550, 351577, 544090, 585057, 634216, 634217, 2239848, 269676, 609645, 560494, 466289, 597363, 634241, 126337, 363906, 605571, 585093, 2289032, 630152, 630157, 593305, 413083, 527771, 597403, 630178, 363939, 548261, 519589, 634279, 482745, 388538, 126394, 515515, 155067, 2047421, 523710, 126395, 630211, 1678800, 527826, 617942, 572891, 564700, 445917, 245217, 634349, 261615, 605688, 507388, 581123, 605703, 626183, 577035, 589327, 445972, 1551895, 122392, 396825, 351775, 1924641, 548386, 556584, 2588201, 556587, 634414, 532020, 634433, 319042, 2641486, 282193, 2367058, 142935, 527964, 536170, 618096, 2686578, 347764, 2616950, 507523, 634500, 601731, 634507, 552590, 560784, 618129, 634512, 2252437, 528023, 1896088, 40604, 548509, 601757, 491170, 585383, 511657, 614059, 503469, 585393, 630449, 200372, 585397, 515774, 2109119, 179904, 335553, 528066, 536261, 630471, 634570, 2555596, 634578, 528083, 544467, 495320, 585433, 577245, 622302, 491232, 573153, 544490, 573166, 585455, 626417, 245494, 585464, 569080, 548602, 634618, 1187586, 626444, 601872, 569108, 2096918, 466714, 622368, 618279, 630573, 634671, 622386, 610099, 2522932, 560951, 630585, 2629436, 2088765, 548677, 626501, 630606, 544594, 626516, 446295, 397149, 601949, 524128, 515936, 630635, 167791, 2178929, 634737, 925553, 536435, 556918, 634744, 593787, 376701, 532350, 577414, 348050, 548764, 593823, 253859, 602030, 606127, 356274, 204725, 626614, 516024, 602042, 315322, 634816, 573377, 483267, 483275, 552913, 585681, 2211797, 536536, 2658268, 585695, 49119, 233444, 634853, 471018, 581614, 610287, 548854, 602107, 151549, 606206}} selected!\n"
     ]
    }
   ],
   "source": [
    "# 6 MaxDT←length(BaseClusterings)\n",
    "maxDT = len(baseClusterings.columns)\n",
    "# 7 BiClust ← {instance sets of FCPs built from MaxDT base clusters}\n",
    "# here BiClust is a list of sets of FCPs build from maxDT baseClusters\n",
    "biClust = []\n",
    "filteredFCP = list(filter(lambda x: len(x) == maxDT, FCPs))\n",
    "filteredFCP.sort(key = str)\n",
    "consVctrs = []\n",
    "for tempSet in filteredFCP:\n",
    "    isInSet = True\n",
    "    for col in tempSet:\n",
    "        isInSet = isInSet & membershipMatrix[col]\n",
    "        \n",
    "    biClust.append(set(baseClusterings.index[isInSet].tolist()))\n",
    "# 8 Assign a label to each set in BiClust to build the first consensus vector and store \n",
    "# it in a list of vectors ConsVctrs\n",
    "assignLabel(biClust, maxDT, consVctrs)\n",
    "# 9 Build the remaining consensuses\n",
    "# 10 for DT = (MaxDT−1) to 1 do\n",
    "for dt in range(maxDT - 1, 0, -1): \n",
    "    filteredFCP = list(filter(lambda x: len(x) == dt, FCPs))\n",
    "    filteredFCP.sort(key = str)\n",
    "    for tempSet in filteredFCP:\n",
    "        isInSet = True\n",
    "        for col in tempSet:\n",
    "            isInSet = isInSet & membershipMatrix[col]\n",
    "#       11 BiClust ← BiClust ∪ {instance sets of FCPs built from DT base clusters}\n",
    "        biClust.append(set(baseClusterings.index[isInSet].tolist()))\n",
    "#   12 Call the consensus function (Algo. 10)\n",
    "    consensusFunction10(biClust)\n",
    "#   13 Assign a label to each set in BiClust to build a consensus vector and add it to \n",
    "#   ConsVctrs\n",
    "    assignLabel(biClust, dt, consVctrs)\n",
    "\n",
    "# 15 Remove similar consensuses\n",
    "# 16 ST ← Vector of ‘1’s of length MaxDT\n",
    "st = [1] * maxDT\n",
    "# 17 for i = MaxDT to 2 do\n",
    "# in python the index starts with 0 -> using maxDT - 1 to 1\n",
    "i = maxDT - 1\n",
    "while i > 0:\n",
    "#   18 Vi ← ith consensus in ConsVctrs\n",
    "    vi = consVctrs[i]\n",
    "#   19 for j = (i−1) to 1 do\n",
    "#   in python the index starts with 0 -> (i−1) to 0\n",
    "    j = i - 1\n",
    "    while j >= 0:\n",
    "#       20 Vj ← jth consensus in ConsVctrs\n",
    "        vj = consVctrs[j]\n",
    "        if jaccard(vi, vj) == 1:\n",
    "            st[i] += 1\n",
    "            del st[j]\n",
    "            del consVctrs[j]\n",
    "            i -= 1\n",
    "            \n",
    "        j -= 1\n",
    "        \n",
    "    i -= 1\n",
    "    \n",
    "# 27 Find the consensus the most similar to the ensemble\n",
    "# 28 L ← length(ConsVctrs)\n",
    "L = len(consVctrs)\n",
    "# 29 TSim ← Vector of ‘0’s of lengthL\n",
    "tSim = [0] * L\n",
    "# 30 for i = 1 to L do\n",
    "for i in range(0, L):\n",
    "#   31 Ci ← ith consensus in ConsVctrs\n",
    "    ci = consVctrs[i]\n",
    "#   here tempArray will be ci converted from dict \n",
    "#   {'maxDT=5|0': {1, 2, 3}, 'maxDT=5|1': {4, 5}, ... }\n",
    "#   to array [0, 0, 0, 1, 1, ...]\n",
    "    tempArray = [-1] * len(baseClusterings.index)\n",
    "    for indx, key in enumerate(ci):\n",
    "        for ii in list(ci[key]):\n",
    "            tempArray[baseClusterings.index.tolist().index(ii)] = indx\n",
    "#   now tempArray is converted and equivalent to ci in the pseudo code\n",
    "#   32 for j = 1 to MaxDT do\n",
    "    for j in range(maxDT):\n",
    "#       33 Cj ← jth clustering in BaseClusterings\n",
    "        cj = baseClusterings.iloc[:,j]\n",
    "#       34 TSim[i] ← TSim[i] + Jaccard(Ci,Cj)\n",
    "        tSim[i] += jaccard_score(tempArray, cj, average='macro')\n",
    "#   36 Sim[i] ← TSim[i] / MaxDT\n",
    "    tSim[i] /= maxDT\n",
    "\n",
    "for i in range(0, len(tSim)):\n",
    "    selectedConsensus = consVctrs[i]\n",
    "#   38 RecommCons ← which.max(TSim)\n",
    "#   we add 'selected' to the corresponding consensus\n",
    "    isSelected = 'selected!' if i == tSim.index(max(tSim)) else ''\n",
    "    clustAlgo_labels = pd.Series(name='consensus', index=baseClusterings.index, dtype='int')\n",
    "    for ii, key in enumerate(selectedConsensus):\n",
    "        for indx in selectedConsensus[key]:\n",
    "            clustAlgo_labels[indx] = ii\n",
    "            \n",
    "#     score = customClusteringScore(encoders, clustAlgo_labels, testY)\n",
    "#     print('stability=%i similarity=%f customScore=%f k=%i %s' % \\\n",
    "#           (st[i], tSim[i], score, clustAlgo_labels.nunique(), isSelected))\n",
    "    print('stability=%i similarity=%f k=%i repartition=%s %s' % \\\n",
    "          (st[i], tSim[i], clustAlgo_labels.nunique(), str(consVctrs[i]), isSelected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e8b291e3cfd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mtempArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbaseClusterings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mindx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trying to improve simirarity by rearrranging the partitions\n",
    "# for example = for clustering [0,0,0,1,1,2,2] trying also:\n",
    "# [1,1,1,0,0,2,2] , [2,2,2,1,1,0,0] , [0,0,0,2,2,1,1], etc...\n",
    "# WARNING: This is REALLY REALLY SLOW ... TODO -> improve performance!\n",
    "\n",
    "L = len(consVctrs)\n",
    "tSim = [0] * L\n",
    "orderedConsVctrs = []\n",
    "for i in range(0, L):\n",
    "    ci = consVctrs[i]\n",
    "    tempSimilaritysVec = []\n",
    "    permutations = []\n",
    "    for perm in itertools.permutations(ci):\n",
    "        tempSimilarity = 0\n",
    "        tempArray = [-1] * len(baseClusterings.index)\n",
    "        indx = 0\n",
    "        for key in perm:\n",
    "            for ii in list(ci[key]):\n",
    "                tempArray[baseClusterings.index.tolist().index(ii)] = indx\n",
    "            indx += 1\n",
    "            \n",
    "        for j in baseClusterings.columns:\n",
    "            cj = baseClusterings[j]\n",
    "            tempSimilarity += jaccard_score(cj, tempArray, average='macro')\n",
    "            \n",
    "        tempSimilaritysVec.append(tempSimilarity/maxDT)\n",
    "        permutations.append(perm)\n",
    "    tSim[i] = max(tempSimilaritysVec)\n",
    "    tempOrderedDict = collections.OrderedDict()\n",
    "    for selectedPermutation in permutations[tempSimilaritysVec.index(tSim[i])]:\n",
    "        tempOrderedDict[selectedPermutation] = ci[selectedPermutation]\n",
    "    orderedConsVctrs.append(tempOrderedDict)\n",
    "\n",
    "for i in range(0, len(tSim)):\n",
    "    selectedConsensus = orderedConsVctrs[i]\n",
    "    isSelected = 'SELECTED!' if i == tSim.index(max(tSim)) else ''\n",
    "    clustAlgo_labels = pd.Series(name='consensus', index=baseClusterings.index, dtype='int')\n",
    "    for ii, key in enumerate(selectedConsensus):\n",
    "        for indx in selectedConsensus[key]:\n",
    "            clustAlgo_labels[indx] = ii\n",
    "            \n",
    "    print('stability=%i similarity=%f k=%i repartition= %s\\n      %s\\n\\\n",
    "___________________________________________________________________' % \\\n",
    "          (st[i], tSim[i], clustAlgo_labels.nunique(), isSelected, str(orderedConsVctrs[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16423589093214966"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = customClusteringScore(clustAlgo_labels, testY)\n",
    "#     print('stability=%i similarity=%f customScore=%f k=%i %s' % \\\n",
    "#           (st[i], tSim[i], score, clustAlgo_labels.nunique(), isSelected))\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_module = 'AAA'\n",
    "code_presentation = '2013J'\n",
    "\n",
    "oneTrainingCourse = filter_oulad.getOneCourse(dataset_dict, code_module, code_presentation)\n",
    "training_final_df = filter_oulad.restructure(oneTrainingCourse, 14)\n",
    "training_encoders = filter_oulad.cleanAndMap(training_final_df)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "trainX = training_final_df.drop(['final_result_first'], axis=1)\n",
    "trainX = scaler.fit_transform(trainX)\n",
    "trainY = training_final_df['final_result_first']\n",
    "\n",
    "code_presentation = '2014J'\n",
    "\n",
    "oneTestCourse = filter_oulad.getOneCourse(dataset_dict, code_module, code_presentation)\n",
    "testing_final_df = filter_oulad.restructure(oneTestCourse, 14)\n",
    "testing_encoders = filter_oulad.cleanAndMap(testing_final_df)\n",
    "\n",
    "testX = testing_final_df.drop(['final_result_first'], axis=1)\n",
    "testX = scaler.fit_transform(testX)\n",
    "testY = testing_final_df['final_result_first']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Deep Learning with Python Design and implement advanced next-generation AI solutions using TensorFlow and PyTorc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "tf.config.list_physical_devices('GPU')\n",
    "# tf.test.is_built_with_cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight\n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)\n",
    "torch.randn(1, 10)\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))\n",
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n",
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU\n",
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "net.to(device)\n",
    "\n",
    "# Remember that you will have to send the inputs and targets at every step to the GPU too:\n",
    "# inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.markers import MarkerStyle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.333\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = trainX.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_vae(intermediate_dim=512, latent_dim=2):\n",
    "    # encoder first\n",
    "    inputs = Input(shape=(image_size,), name='encoder_input')\n",
    "    x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    # latent mean and variance\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "    # Reparameterization trick for random sampling    \n",
    "    # Note the use of the Lambda layer    \n",
    "    # At runtime, it will call the sampling function\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,),name='z')([z_mean, z_log_var])\n",
    "    # full encoder encoder model\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    encoder.summary()\n",
    "    \n",
    "    # decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(image_size, activation='sigmoid')(x)\n",
    "    # full decoder model\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "    decoder.summary()\n",
    "    # VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = Model(inputs, outputs, name='vae')\n",
    "    # Loss function   \n",
    "    # we start with the reconstruction loss\n",
    "    reconstruction_loss = binary_crossentropy(inputs, outputs) * image_size\n",
    "    # next is the KL divergence\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    # we combine them in a total loss\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    return encoder, decoder, vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args: tuple):\n",
    "    \"\"\":param args: (tensor, tensor) mean and log of variance of    q(z|x)    \"\"\"\n",
    "    # unpack the input tuple\n",
    "    z_mean, z_log_var = args\n",
    "    # mini-batch sizem\n",
    "    mb_size = K.shape(z_mean)[0]\n",
    "    # latent space size\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # random normal vector with mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(mb_size, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder, decoder, vae = build_vae()\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n",
    "vae.fit(trainX, epochs=50, batch_size=128, validation_data=(testX, None))\n",
    "vae.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WIP Doing without understanding (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(40, activation='relu', input_shape=(trainX.shape[1],)))\n",
    "# network.add(layers.Dense(1000, activation='relu'))\n",
    "network.add(layers.Dense(30, activation='relu'))\n",
    "network.add(layers.Dense(4, activation='softmax'))\n",
    "network.compile(optimizer='rmsprop', # optimizers.RMSprop(lr=0.001)\n",
    "                loss='categorical_crossentropy', # binary_crossentropy\n",
    "                metrics=['accuracy'])\n",
    "history = network.fit(trainX, pd.get_dummies(trainY), epochs=5, batch_size=50, \n",
    "                      validation_split=0.75,\n",
    "                     validation_data=(testX, pd.get_dummies(testY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = network.evaluate(testX, pd.get_dummies(testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()   # clear figure\n",
    "acc_values = history.history['accuracy']\n",
    "val_acc_values = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for value in network.predict(testX):\n",
    "    predictions.append(np.argmax(value))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(testY, predictions, labels=[0,1,2,3]), \\\n",
    "             columns=index1, index=index2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
